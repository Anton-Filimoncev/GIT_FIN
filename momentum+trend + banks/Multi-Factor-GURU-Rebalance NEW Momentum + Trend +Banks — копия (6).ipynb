{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from pandas_datareader.famafrench import get_available_datasets\n",
    "import pandas_datareader.data as web\n",
    "from yahoo_fin import stock_info as si\n",
    "from performance_analysis import annualized_return\n",
    "from performance_analysis import annualized_standard_deviation\n",
    "from performance_analysis import max_drawdown\n",
    "from performance_analysis import gain_to_pain_ratio\n",
    "from performance_analysis import calmar_ratio\n",
    "from performance_analysis import sharpe_ratio\n",
    "from performance_analysis import sortino_ratio\n",
    "import yfinance as yf\n",
    "import apiclient.discovery\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import httplib2\n",
    "from sklearn import mixture as mix\n",
    "import seaborn as sns \n",
    "import gspread as gd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SGX:K3PD', 'SGX:K3OD', 'SGX:D05', 'SGX:O39', 'SGX:K6S', 'SGX:U11', 'SGX:J36', 'SGX:K3SD', 'SGX:Z77', 'SGX:Z74', 'SGX:F34', 'SGX:K3ED', 'SGX:S07', 'SGX:C31', 'SGX:K3ID', 'SGX:K3RD', 'SGX:Y92', 'SGX:Q0F', 'SGX:C6L', 'SGX:C38U', 'SGX:A17U', 'SGX:S63', 'SGX:K3HD', 'SGX:S68', 'SGX:G07', 'SGX:H78', 'SGX:BN4', 'SGX:BVA', 'SGX:G13', 'SGX:M44U', 'SGX:C07', 'SGX:ME8U', 'SGX:N2IU', 'SGX:C09', 'SGX:U14', 'SGX:BS6', 'SGX:V03', 'SGX:K3FD', 'SGX:BUOU', 'SGX:K3DD', 'SGX:AZY', 'SGX:D01', 'SGX:O32', 'SGX:S58', 'SGX:AJBU', 'SGX:K71U', 'SGX:T82U', 'SGX:T15', 'SGX:J69U', 'SGX:MZH', 'SGX:STG', 'SGX:U06', 'SGX:CJLU', 'SGX:U96', 'SGX:RW0U', 'SGX:C52', 'SGX:TQ5', 'SGX:HMN', 'SGX:HKB', 'SGX:T39', 'SGX:E5H', 'SGX:H02', 'SGX:C2PU', 'SGX:T14', 'SGX:A7RU', 'SGX:BSL', 'SGX:NC2', 'SGX:M04', 'SGX:SK6U', 'SGX:AIY', 'SGX:S59', 'SGX:A50', 'SGX:OV8', 'SGX:TS0U', 'SGX:EB5', 'SGX:CC3', 'SGX:Z25', 'SGX:F99', 'SGX:NS8U', 'SGX:AU8U', 'SGX:H13', 'SGX:AP4', 'SGX:F17', 'SGX:J91U', 'SGX:H15', 'SGX:CY6U', 'SGX:UD2', 'SGX:S08', 'SGX:J85', 'SGX:U10', 'SGX:CWBU', 'SGX:W05', 'SGX:S51', 'SGX:ADN', 'SGX:P40U', 'SGX:B61', 'SGX:K2LU', 'SGX:S20', 'SGX:A26', 'SGX:BTOU', 'SGX:EH5', 'SGX:LJ3', 'SGX:Q5T', 'SGX:AWX', 'SGX:CRPU', 'SGX:S41', 'SGX:O5RU', 'SGX:JYEU', 'SGX:AGS', 'SGX:P15', 'SGX:ACV', 'SGX:5UX', 'SGX:558', 'SGX:S61', 'SGX:E28', 'SGX:8AZ', 'SGX:F31', 'SGX:579', 'SGX:OXMU', 'SGX:G92', 'SGX:AUE', 'SGX:CHZ', 'SGX:P8Z', 'SGX:ADQU', 'SGX:H18', 'SGX:U9E', 'SGX:5CP', 'SGX:WJP', 'SGX:OYY', 'SGX:E27', 'SGX:CMOU', 'SGX:D03', 'SGX:5IG', 'SGX:H30', 'SGX:XJB', 'SGX:H22', 'SGX:BWCU', 'SGX:MV4', 'SGX:F83', 'SGX:T24', 'SGX:QC7', 'SGX:M30', 'SGX:M01', 'SGX:BWM', 'SGX:UD1U', 'SGX:E8Z', 'SGX:Q01', 'SGX:Y03', 'SGX:P34', 'SGX:5G3', 'SGX:5GD', 'SGX:O10', 'SGX:QES', 'SGX:F9D', 'SGX:BHK', 'SGX:QNS', 'SGX:D5IU', 'SGX:1D0', 'SGX:L09', 'SGX:M1GU', 'SGX:C41', 'SGX:5DD', 'SGX:546', 'SGX:S85', 'SGX:5JS', 'SGX:F03', 'SGX:U13', 'SGX:AW9U', 'SGX:5VJ', 'SGX:CEDU', 'SGX:B28', 'SGX:BTE', 'SGX:5H0', 'SGX:H07', 'SGX:JLB', 'SGX:VL6', 'SGX:P9D', 'SGX:ODBU', 'SGX:BEC', 'SGX:5EN', 'SGX:G41', 'SGX:C29', 'SGX:8K7', 'SGX:I07', 'SGX:F1E', 'SGX:RE4', 'SGX:BDX', 'SGX:AVM', 'SGX:MXNU', 'SGX:N02', 'SGX:H12', 'SGX:5JK', 'SGX:5WH', 'SGX:Z59', 'SGX:BMGU', 'SGX:TCU', 'SGX:5WE', 'SGX:CLN', 'SGX:XZL', 'SGX:OU8']\n"
     ]
    }
   ],
   "source": [
    "# подключение к гугл таблице\n",
    "\n",
    "LIST = 'Сингапур'\n",
    "\n",
    "index = '^AXJO'\n",
    "\n",
    "exchange = 'SGX:'\n",
    "\n",
    "exchange_yahoo =  '.SI'\n",
    "\n",
    "# tickers = si.tickers_sp500()\n",
    "cheked_year = '2015' \n",
    "cheked_year_end = '2020' \n",
    "\n",
    "\n",
    "# Файл, полученный в Google Developer Console\n",
    "CREDENTIALS_FILE = 'Seetzzz-1cb93f64d8d7.json'\n",
    "# ID Google Sheets документа (можно взять из его URL)\n",
    "spreadsheet_id = '1lDhu6-tBmoh66a1mY3RU2yPV2_3uIzNSQWNI5UtMcag'\n",
    "spreadsheet_id2 = '1A3leW6ZfsoVEPXZsv0Loj4eAbyKRchnHrJLdP4RIXDA'\n",
    "#\n",
    "# Авторизуемся и получаем service — экземпляр доступа к API\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "    CREDENTIALS_FILE,\n",
    "    ['https://www.googleapis.com/auth/spreadsheets',\n",
    "     'https://www.googleapis.com/auth/drive'])\n",
    "httpAuth = credentials.authorize(httplib2.Http())\n",
    "service = apiclient.discovery.build('sheets', 'v4', http=httpAuth)\n",
    "\n",
    "# ____________________________Парсим тикеры !!!!С ТАБЛИЦЫ!!!! и работаем с ними _______________________________________\n",
    "\n",
    "# Чтения файла\n",
    "values = service.spreadsheets().values().get(\n",
    "    spreadsheetId=spreadsheet_id,\n",
    "    range=f'{LIST}!A1:AA1000',\n",
    "    majorDimension='COLUMNS'\n",
    ").execute()\n",
    "\n",
    "tickers = values['values'][12][2:202]\n",
    "\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Читаем данные из огурцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-9cb4da001a8e>:204: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  div_yield_list.append((Data_for_Portfolio['Div Yield'][year_div+1] - Data_for_Portfolio['Div Yield'][year_div])/ Data_for_Portfolio['Div Yield'][year_div]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:213: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dividend_payout_ratio_list.append((common_size_ratios_df['Dividend Payout Ratio'][year_div+1] - common_size_ratios_df['Dividend Payout Ratio'][year_div])/ common_size_ratios_df['Dividend Payout Ratio'][year_div]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:213: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  dividend_payout_ratio_list.append((common_size_ratios_df['Dividend Payout Ratio'][year_div+1] - common_size_ratios_df['Dividend Payout Ratio'][year_div])/ common_size_ratios_df['Dividend Payout Ratio'][year_div]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:204: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  div_yield_list.append((Data_for_Portfolio['Div Yield'][year_div+1] - Data_for_Portfolio['Div Yield'][year_div])/ Data_for_Portfolio['Div Yield'][year_div]*100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGX:K6S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-9cb4da001a8e>:126: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  EPS_grows_list.append((per_share_data_df['EPS without NRI'][year+1] - per_share_data_df['EPS without NRI'][year])/ per_share_data_df['EPS without NRI'][year]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:208: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  book_value_per_share_list.append((per_share_data_df['Book Value per Share'][year_div+1] - per_share_data_df['Book Value per Share'][year_div])/ per_share_data_df['Book Value per Share'][year_div]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:130: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  rvenue_grows_list.append((income_df['Revenue'][year+1] - income_df['Revenue'][year])/ income_df['Revenue'][year]*100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGX:G07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-9cb4da001a8e>:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  total_equity_grows_list.append((balance_df['Total Equity'][year+1] - balance_df['Total Equity'][year])/ balance_df['Total Equity'][year]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:122: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  total_equity_grows_list.append((balance_df['Total Equity'][year+1] - balance_df['Total Equity'][year])/ balance_df['Total Equity'][year]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:208: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  book_value_per_share_list.append((per_share_data_df['Book Value per Share'][year_div+1] - per_share_data_df['Book Value per Share'][year_div])/ per_share_data_df['Book Value per Share'][year_div]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:126: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  EPS_grows_list.append((per_share_data_df['EPS without NRI'][year+1] - per_share_data_df['EPS without NRI'][year])/ per_share_data_df['EPS without NRI'][year]*100)\n",
      "<ipython-input-3-9cb4da001a8e>:130: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rvenue_grows_list.append((income_df['Revenue'][year+1] - income_df['Revenue'][year])/ income_df['Revenue'][year]*100)\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:178: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGX:JYEU\n",
      "SGX:U13\n",
      "SGX:MXNU\n"
     ]
    }
   ],
   "source": [
    "# # ['annuals']\n",
    "\n",
    "Data_for_Portfolio_TOTAL = pd.DataFrame()\n",
    " \n",
    "for ticker in tickers:\n",
    "    with open(f'''C:/Users/Anton/Desktop/Backtesting/BANKA/data_json_{ticker.replace(exchange, '')}.pickle''', 'rb') as f:\n",
    "        data_json = pickle.load(f)\n",
    "\n",
    "    with open(f'''C:/Users/Anton/Desktop/Backtesting/BANKA/data_json_keyratios_{ticker.replace(exchange, '')}.pickle''', 'rb') as f:\n",
    "        data_json_keyratios = pickle.load(f)\n",
    "\n",
    "#     print(data_json)    \n",
    "    try:\n",
    "        date_list = pd.Series(data_json['financials']['annuals']['Fiscal Year'])\n",
    "        keyratios = pd.DataFrame(data_json_keyratios['Fundamental'], index=[0]) \n",
    "        income_df = pd.DataFrame(data_json['financials']['annuals']['income_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('', 0).replace('N/A', 0).astype(float)\n",
    "        balance_df = pd.DataFrame(data_json['financials']['annuals']['balance_sheet']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        cashflow_df = pd.DataFrame(data_json['financials']['annuals']['cashflow_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        valuation_ratios_df = pd.DataFrame(data_json['financials']['annuals']['valuation_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        valuation_and_quality_df = pd.DataFrame(data_json['financials']['annuals']['valuation_and_quality']).set_index(date_list).drop(['Restated Filing Date', 'Filing Date', 'Earnings Release Date'], axis=1).replace('', 0).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        common_size_ratios_df = pd.DataFrame(data_json['financials']['annuals']['common_size_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).replace('Negative Tangible Equity', 0).astype(float)\n",
    "        # per_share_data_array_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        per_share_data_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('', 0).replace('No Debt', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        \n",
    "        check = 1\n",
    "    except:\n",
    "        check = 0\n",
    "        print(ticker)\n",
    "        \n",
    "        pass\n",
    "            \n",
    "    if check == 1:\n",
    "    \n",
    "        try:\n",
    "\n",
    "            Data_for_Portfolio = pd.DataFrame()\n",
    "        #     \n",
    "            Data_for_Portfolio['E/P'] = income_df['Net Income'] / valuation_and_quality_df['Market Cap'] \n",
    "            # income_df['Net Income']\n",
    "            # valuation_and_quality_df.replace('-', 0)\n",
    "\n",
    "\n",
    "    #             Data_for_Portfolio['EBITDA/EV'] = income_df['EBITDA'] / (valuation_and_quality_df['Enterprise Value ($M)']*1000000)\n",
    "            try:\n",
    "                Data_for_Portfolio['EBITDA/EV'] = 1/valuation_ratios_df['EV-to-EBITDA']\n",
    "            except:\n",
    "                Data_for_Portfolio['EBITDA/EV'] = income_df['Pretax Income'] / valuation_and_quality_df['Enterprise Value ($M)']\n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['ncfcommon'] = cashflow_df['Free Cash Flow']/(valuation_and_quality_df['Shares Outstanding (EOP)']**1000)\n",
    "\n",
    "    #             try:    \n",
    "    #                 Data_for_Portfolio['Total Debt'] = (balance_df['Short-Term Debt'] + balance_df['Long-Term Debt'])\n",
    "            Data_for_Portfolio['Total Debt'] =per_share_data_df['Total Debt per Share']*(valuation_and_quality_df['Shares Outstanding (EOP)']*1000)\n",
    "    #             except:\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['Shareholder Yield'] = -((Data_for_Portfolio['Total Debt'] + cashflow_df['Free Cash Flow'] \\\n",
    "                                             + Data_for_Portfolio['ncfcommon']) / valuation_and_quality_df['Market Cap'])\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['FCF/P'] = cashflow_df['Free Cash Flow'] / valuation_and_quality_df['Market Cap']\n",
    "            Data_for_Portfolio\n",
    "            # Data_for_Portfolio['Shareholder Yield'] \n",
    "            Data_for_Portfolio['Book Value per Share'] = per_share_data_df['Book Value per Share']\n",
    "            Data_for_Portfolio['Dividends per Share'] =per_share_data_df['Dividends per Share'] \n",
    "            Data_for_Portfolio['Dividend Payout Ratio'] =common_size_ratios_df['Dividend Payout Ratio']\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Current Assets']\n",
    "            except:\n",
    "                Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / (balance_df['Balance Statement Cash and cash equivalents'] + balance_df['Accounts Receivable'])                                   \n",
    "\n",
    "            #Can you generate returns on investment?   \n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['ROA'] = common_size_ratios_df['ROA %']  \n",
    "            Data_for_Portfolio['ROIC'] = common_size_ratios_df['ROIC %']\n",
    "            #Do you have a defendable business model?\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Gross Margin %']\n",
    "\n",
    "            except:\n",
    "                Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Net Interest Margin (Bank Only) %']\n",
    "\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['CURRENT RATIO'] = valuation_and_quality_df['Current Ratio'] \n",
    "            except:\n",
    "                Data_for_Portfolio['CURRENT RATIO'] = 1/common_size_ratios_df['Debt-to-Equity']\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['EBITDA']\n",
    "            except:\n",
    "                Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['Pretax Income']\n",
    "\n",
    "#             print('tut')    \n",
    "   \n",
    "                \n",
    "    # balance_df['Total Equity']\n",
    "    # per_share_data_df['EPS without NRI']\n",
    "    # income_df['Revenue']\n",
    "    # income_df['Net Margin %']\n",
    "\n",
    "            total_equity_grows_list = []\n",
    "            EPS_grows_list = []\n",
    "            rvenue_grows_list = []\n",
    "\n",
    "        #  (500-400)/400*100=25%\n",
    "\n",
    "\n",
    "            total_equity_grows_list.append(0)\n",
    "            EPS_grows_list.append(0)\n",
    "            rvenue_grows_list.append(0)\n",
    "\n",
    "            for year in range(len(Data_for_Portfolio)):\n",
    "\n",
    "                try:\n",
    "                    total_equity_grows_list.append((balance_df['Total Equity'][year+1] - balance_df['Total Equity'][year])/ balance_df['Total Equity'][year]*100)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    EPS_grows_list.append((per_share_data_df['EPS without NRI'][year+1] - per_share_data_df['EPS without NRI'][year])/ per_share_data_df['EPS without NRI'][year]*100)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    rvenue_grows_list.append((income_df['Revenue'][year+1] - income_df['Revenue'][year])/ income_df['Revenue'][year]*100)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                \n",
    "                \n",
    "            mean_total_equity_grows_list = [0, 0, 0, 0]\n",
    "            mean_EPS_grows_list = [0, 0, 0, 0]\n",
    "            mean_rvenue_grows_list = [0, 0, 0, 0]\n",
    "            margin_params_list = [0, 0, 0, 0]\n",
    "\n",
    "            for yearzz in range(len(Data_for_Portfolio)):\n",
    "                if len(total_equity_grows_list[yearzz:5+yearzz])  == 5:\n",
    "                    mean_total_equity_grows_list.append(np.mean(total_equity_grows_list[yearzz:5+yearzz]))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if len(EPS_grows_list[yearzz:5+yearzz])  == 5:\n",
    "                    mean_EPS_grows_list.append(np.mean(EPS_grows_list[yearzz:5+yearzz]))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if len(rvenue_grows_list[yearzz:5+yearzz])  == 5:\n",
    "                    mean_rvenue_grows_list.append(np.mean(rvenue_grows_list[yearzz:5+yearzz]))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            Data_for_Portfolio['Net Margin %'] = income_df['Net Margin %']   \n",
    "\n",
    "\n",
    "             \n",
    "            \n",
    "            for k in range(len(Data_for_Portfolio)):\n",
    "    #             print(len(Data_for_Portfolio['Net Margin %'][k:5+k]))\n",
    "                if len(Data_for_Portfolio['Net Margin %'][k:5+k])  == 5:\n",
    "                    Y = Data_for_Portfolio['Net Margin %'][k:5+k].astype(float)\n",
    "                    X = list(range(len(date_list[k:5+k])))\n",
    "                    # X = sm.add_constant(X)\n",
    "                    model = sm.OLS(Y,X)\n",
    "                    results = model.fit()\n",
    "                    margin_params_list.append(results.params[0])\n",
    "    #                 print(results.params[0])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    #         print(margin_params_list)\n",
    "    #         print(Data_for_Portfolio['Net Margin %'])\n",
    "\n",
    "#             print('tut22')\n",
    "    \n",
    "    \n",
    "            Data_for_Portfolio['Total Equity Grows 5Y'] = mean_total_equity_grows_list\n",
    "            Data_for_Portfolio['EPS without NRI Grows 5Y'] = mean_EPS_grows_list\n",
    "            Data_for_Portfolio['Revenue Grows 5Y'] = mean_rvenue_grows_list\n",
    "            Data_for_Portfolio['Net Margin % params'] = margin_params_list\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "#             print('tut2')  \n",
    "            \n",
    "            \n",
    "\n",
    "            Data_for_Portfolio['Div Yield'] = valuation_and_quality_df['Buyback Yield %'] + valuation_ratios_df['Dividend Yield %']\n",
    "\n",
    "            div_yield_list = [0]\n",
    "            book_value_per_share_list = [0]\n",
    "            dividend_payout_ratio_list = [0]\n",
    "\n",
    "        #  (500-400)/400*100=25%\n",
    "\n",
    "            for year_div in range(len(Data_for_Portfolio)):\n",
    "\n",
    "                try:\n",
    "                    div_yield_list.append((Data_for_Portfolio['Div Yield'][year_div+1] - Data_for_Portfolio['Div Yield'][year_div])/ Data_for_Portfolio['Div Yield'][year_div]*100)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    book_value_per_share_list.append((per_share_data_df['Book Value per Share'][year_div+1] - per_share_data_df['Book Value per Share'][year_div])/ per_share_data_df['Book Value per Share'][year_div]*100)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    dividend_payout_ratio_list.append((common_size_ratios_df['Dividend Payout Ratio'][year_div+1] - common_size_ratios_df['Dividend Payout Ratio'][year_div])/ common_size_ratios_df['Dividend Payout Ratio'][year_div]*100)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "            div_yield_list_5y = [0, 0, 0, 0, 0]\n",
    "            book_value_per_share_list_5y = [0, 0, 0, 0, 0]\n",
    "            dividend_payout_ratio_list_5y = [0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "            for year_div_5 in range(len(Data_for_Portfolio)):\n",
    "                if len(total_equity_grows_list[year_div_5:5+year_div_5])  == 5:\n",
    "                    mean_total_equity_grows_list.append(np.mean(total_equity_grows_list[year_div_5:5+year_div_5]))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if len(EPS_grows_list[year_div_5:5+year_div_5])  == 5:\n",
    "                    mean_EPS_grows_list.append(np.mean(EPS_grows_list[year_div_5:5+year_div_5]))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if len(rvenue_grows_list[year_div_5:5+year_div_5])  == 5:\n",
    "                    mean_rvenue_grows_list.append(np.mean(dividend_payout_ratio_list[year_div_5:5+year_div_5]))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['Book Value per Share 5Y'] = book_value_per_share_list\n",
    "            Data_for_Portfolio['Div Yield 5Y'] = div_yield_list\n",
    "            Data_for_Portfolio['Dividend Payout Ratio 5Y'] = dividend_payout_ratio_list\n",
    "\n",
    "#             print('tut2')\n",
    "\n",
    "    #             regression = pd.ols(y=Data_for_Portfolio['Net Margin %'], x=date_list)\n",
    "    #             print(regression.summary)\n",
    "\n",
    "    #             Data_for_Portfolio['Total Equity Grows'] = total_equity_grows_list\n",
    "    #             Data_for_Portfolio['EPS without NRI Grows'] = EPS_grows_list\n",
    "    #             Data_for_Portfolio['Revenue Grows'] = rvenue_grows_list\n",
    "    #             Data_for_Portfolio['Net Margin %'] = income_df['Net Margin %']\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['Company'] = ticker\n",
    "            Data_for_Portfolio['Date'] = list(date_list)\n",
    "\n",
    "            Data_for_Portfolio = Data_for_Portfolio.replace([np.inf, -np.inf], 0)\n",
    "            Data_for_Portfolio = Data_for_Portfolio.set_index('Company')\n",
    "            Data_for_Portfolio = Data_for_Portfolio[::-1].fillna(0)\n",
    "\n",
    "            sumz_frame= [Data_for_Portfolio, Data_for_Portfolio_TOTAL]\n",
    "            Data_for_Portfolio_TOTAL = pd.concat(sumz_frame)\n",
    "\n",
    "        except:\n",
    "            print(ticker)\n",
    "            pass\n",
    "\n",
    "#         print(list(date_list))\n",
    "# list(set(Data_for_Portfolio_TOTAL.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(Data_for_Portfolio_TOTAL.index.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(Data_for_Portfolio_TOTAL.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ['annuals']\n",
    "\n",
    "# tickers = si.tickers_sp500()\n",
    "\n",
    "# Data_for_Portfolio_TOTAL = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# for ticker in tickers:\n",
    "#     with open(f'BANKA/data_json_{ticker}.pickle', 'rb') as f:\n",
    "#         data_json = pickle.load(f)\n",
    "\n",
    "#     with open(f'BANKA/data_json_keyratios_{ticker}.pickle', 'rb') as f:\n",
    "#         data_json_keyratios = pickle.load(f)\n",
    "\n",
    "# #     print(data_json)    \n",
    "#     try:\n",
    "#         date_list = pd.Series(data_json['financials']['annuals']['Fiscal Year'])\n",
    "#         keyratios = pd.DataFrame(data_json_keyratios['Fundamental'], index=[0]) \n",
    "#         income_df = pd.DataFrame(data_json['financials']['annuals']['income_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('', 0).replace('N/A', 0).astype(float)\n",
    "#         balance_df = pd.DataFrame(data_json['financials']['annuals']['balance_sheet']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         cashflow_df = pd.DataFrame(data_json['financials']['annuals']['cashflow_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         valuation_ratios_df = pd.DataFrame(data_json['financials']['annuals']['valuation_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         valuation_and_quality_df = pd.DataFrame(data_json['financials']['annuals']['valuation_and_quality']).set_index(date_list).drop(['Restated Filing Date', 'Filing Date', 'Earnings Release Date'], axis=1).replace('', 0).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         common_size_ratios_df = pd.DataFrame(data_json['financials']['annuals']['common_size_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).replace('Negative Tangible Equity', 0).astype(float)\n",
    "#         # per_share_data_array_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         per_share_data_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('', 0).replace('No Debt', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        \n",
    "#         check = 1\n",
    "#     except:\n",
    "#         pass\n",
    "            \n",
    "#     if check == 1:\n",
    "    \n",
    "#         Data_for_Portfolio = pd.DataFrame()\n",
    "#     #     \n",
    "#         Data_for_Portfolio['E/P'] = income_df['Net Income'] / valuation_and_quality_df['Market Cap'] \n",
    "#         # income_df['Net Income']\n",
    "#         # valuation_and_quality_df.replace('-', 0)\n",
    "#         Data_for_Portfolio\n",
    "#         try:\n",
    "#             Data_for_Portfolio['EBITDA/EV'] = income_df['EBITDA'] / (valuation_and_quality_df['Enterprise Value ($M)']*1000000)\n",
    "#         except:\n",
    "#             Data_for_Portfolio['EBITDA/EV'] = Data_for_Portfolio['E/P'] * 0\n",
    "\n",
    "#         Data_for_Portfolio['ncfcommon'] = cashflow_df['Free Cash Flow']/valuation_and_quality_df['Shares Outstanding (EOP)']\n",
    "#         try:\n",
    "#             Data_for_Portfolio['Total Debt'] = (balance_df['Short-Term Debt'] + balance_df['Long-Term Debt'])\n",
    "#         except:\n",
    "#             Data_for_Portfolio['Total Debt'] = Data_for_Portfolio['ncfcommon'] * 0\n",
    "# #             print(Data_for_Portfolio)\n",
    "\n",
    "#         Data_for_Portfolio['Shareholder Yield'] = -((Data_for_Portfolio['Total Debt'] + cashflow_df['Free Cash Flow'] \\\n",
    "#                                          + Data_for_Portfolio['ncfcommon']) / valuation_and_quality_df['Market Cap'])\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['FCF/P'] = cashflow_df['Free Cash Flow'] / valuation_and_quality_df['Market Cap']\n",
    "#         Data_for_Portfolio\n",
    "#         # Data_for_Portfolio['Shareholder Yield'] \n",
    "#         Data_for_Portfolio['Book Value per Share'] = per_share_data_df['Book Value per Share']\n",
    "#         Data_for_Portfolio['Dividends per Share'] =per_share_data_df['Dividends per Share'] \n",
    "#         Data_for_Portfolio['Dividend Payout Ratio'] =common_size_ratios_df['Dividend Payout Ratio']\n",
    "\n",
    "#         try:\n",
    "#             Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Current Assets']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Assets']\n",
    "#         #Can you generate returns on investment?   \n",
    "\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['ROA'] = common_size_ratios_df['ROA %']  \n",
    "#         Data_for_Portfolio['ROIC'] = common_size_ratios_df['ROIC %']\n",
    "#         #Do you have a defendable business model?\n",
    "#         try:\n",
    "#             Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Gross Margin %']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['GROSS MARGIN'] = Data_for_Portfolio['ROA'] * 0\n",
    "#         #Current Financial Strength\n",
    "#         try:\n",
    "#             Data_for_Portfolio['CURRENT RATIO'] = balance_df['Total Current Assets'] / balance_df['Total Current Liabilities']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['CURRENT RATIO'] = balance_df['Total Assets'] / balance_df['Total Liabilities']\n",
    "\n",
    "\n",
    "#         try:\n",
    "#             Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['EBITDA']\n",
    "#         except:\n",
    "#             try:\n",
    "#                 Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense (Positive)'] / income_df['EBITDA']\n",
    "#             except:\n",
    "#                 Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['Company'] = ticker\n",
    "#         Data_for_Portfolio['Date'] = list(date_list)\n",
    "\n",
    "#         Data_for_Portfolio = Data_for_Portfolio.replace([np.inf, -np.inf], 0)\n",
    "#         Data_for_Portfolio = Data_for_Portfolio.set_index('Company')\n",
    "#         Data_for_Portfolio = Data_for_Portfolio[::-1]\n",
    "\n",
    "#         sumz_frame= [Data_for_Portfolio, Data_for_Portfolio_TOTAL]\n",
    "#         Data_for_Portfolio_TOTAL = pd.concat(sumz_frame)\n",
    "\n",
    "\n",
    "\n",
    "# #         print(list(date_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  200 of 200 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADQU.SI: No data found, symbol may be delisted\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CLN.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VL6.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JLB.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CEDU.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- 1D0.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BWM.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BWCU.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OYY.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADQU.SI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CHZ.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BTOU.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CJLU.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STG.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BUOU.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BVA.SI: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-7-8040e5107bdb>:388: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod()\n",
      "<ipython-input-7-8040e5107bdb>:419: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2016-1-1\n",
      "[49.11992688307967]\n",
      "top_rated_company\n",
      "['SGX:QES', 'SGX:P9D', 'SGX:558', 'SGX:K3SD', 'SGX:S85', 'SGX:5DD', 'SGX:5CP', 'SGX:5G3', 'SGX:WJP', 'SGX:S68', 'SGX:F1E', 'SGX:P15', 'SGX:OU8', 'SGX:EH5', 'SGX:ME8U', 'SGX:L09', 'SGX:S41', 'SGX:J69U', 'SGX:AP4', 'SGX:A17U', 'SGX:W05', 'SGX:C2PU', 'SGX:K3RD', 'SGX:H30', 'SGX:O5RU', 'SGX:O39', 'SGX:QC7', 'SGX:H02', 'SGX:C29', 'SGX:CHZ', 'SGX:M01', 'SGX:OV8', 'SGX:1D0', 'SGX:HMN', 'SGX:B61', 'SGX:BHK']\n",
      "low_rated_company\n",
      "['SGX:O32', 'SGX:F34', 'SGX:K3OD', 'SGX:ADN', 'SGX:CJLU', 'SGX:5EN', 'SGX:ADQU', 'SGX:BWM', 'SGX:STG', 'SGX:P34', 'SGX:TQ5', 'SGX:S20', 'SGX:E5H', 'SGX:RE4', 'SGX:CLN', 'SGX:A50', 'SGX:S07', 'SGX:NC2', 'SGX:U96', 'SGX:MV4', 'SGX:LJ3', 'SGX:S61', 'SGX:5JS', 'SGX:E27', 'SGX:M1GU', 'SGX:JLB', 'SGX:P40U', 'SGX:H22', 'SGX:BWCU', 'SGX:ACV', 'SGX:5IG', 'SGX:579', 'SGX:K3HD', 'SGX:S51', 'SGX:5WH', 'SGX:F83']\n",
      "Max DD\n",
      "[-64.22764345835105]\n",
      "-64.22764345835105\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- XZL.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CLN.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VL6.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JLB.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CEDU.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- 1D0.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CMOU.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OYY.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADQU.SI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CHZ.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OXMU.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HKB.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CJLU.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STG.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MZH.SI: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-7-8040e5107bdb>:388: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod()\n",
      "<ipython-input-7-8040e5107bdb>:419: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2017-1-1\n",
      "[49.11992688307967, 34.031798019321634]\n",
      "top_rated_company\n",
      "['SGX:RE4', 'SGX:5G3', 'SGX:QES', 'SGX:5DD', 'SGX:S85', 'SGX:L09', 'SGX:F1E', 'SGX:EH5', 'SGX:5CP', 'SGX:P9D', 'SGX:S68', 'SGX:5H0', 'SGX:QC7', 'SGX:Z25', 'SGX:5UX', 'SGX:Q01', 'SGX:N2IU', 'SGX:C41', 'SGX:F03', 'SGX:N02', 'SGX:ME8U', 'SGX:AZY', 'SGX:CC3', 'SGX:558', 'SGX:M30', 'SGX:H78', 'SGX:CY6U', 'SGX:K3DD', 'SGX:P15', 'SGX:J91U', 'SGX:A17U', 'SGX:AP4', 'SGX:BS6', 'SGX:J69U', 'SGX:WJP', 'SGX:O39', 'SGX:F17']\n",
      "low_rated_company\n",
      "['SGX:546', 'SGX:BN4', 'SGX:S20', 'SGX:E8Z', 'SGX:5JS', 'SGX:CEDU', 'SGX:O32', 'SGX:S08', 'SGX:S07', 'SGX:U96', 'SGX:BWM', 'SGX:CLN', 'SGX:5WH', 'SGX:C6L', 'SGX:CMOU', 'SGX:K3ID', 'SGX:OXMU', 'SGX:5IG', 'SGX:S41', 'SGX:5JK', 'SGX:5EN', 'SGX:XZL', 'SGX:NS8U', 'SGX:S51', 'SGX:C29', 'SGX:BUOU', 'SGX:JLB', 'SGX:M1GU', 'SGX:NC2', 'SGX:H22', 'SGX:579', 'SGX:MZH', 'SGX:HKB', 'SGX:BMGU', 'SGX:E27', 'SGX:K3HD', 'SGX:F83']\n",
      "Max DD\n",
      "[-64.22764345835105, -64.61538324871003]\n",
      "-64.61538324871003\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- XZL.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TCU.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ODBU.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- VL6.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JLB.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- QNS.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OYY.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADQU.SI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OXMU.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- 8AZ.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CRPU.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HKB.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STG.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MZH.SI: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-7-8040e5107bdb>:388: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod()\n",
      "<ipython-input-7-8040e5107bdb>:419: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2018-1-1\n",
      "[49.11992688307967, 34.031798019321634, -8.901456292050778]\n",
      "top_rated_company\n",
      "['SGX:5CP', 'SGX:5G3', 'SGX:QES', 'SGX:AWX', 'SGX:5H0', 'SGX:C41', 'SGX:5DD', 'SGX:S85', 'SGX:H07', 'SGX:AUE', 'SGX:RE4', 'SGX:H78', 'SGX:L09', 'SGX:5JK', 'SGX:RW0U', 'SGX:A26', 'SGX:N2IU', 'SGX:558', 'SGX:F99', 'SGX:5UX', 'SGX:S68', 'SGX:CHZ', 'SGX:1D0', 'SGX:H02', 'SGX:ME8U', 'SGX:Q5T', 'SGX:K3RD', 'SGX:J69U', 'SGX:C2PU', 'SGX:AGS', 'SGX:E27', 'SGX:BUOU', 'SGX:W05', 'SGX:CEDU', 'SGX:K3DD', 'SGX:CC3', 'SGX:K3PD', 'SGX:WJP']\n",
      "low_rated_company\n",
      "['SGX:D03', 'SGX:BHK', 'SGX:BEC', 'SGX:N02', 'SGX:F17', 'SGX:BN4', 'SGX:F31', 'SGX:E8Z', 'SGX:U96', 'SGX:S51', 'SGX:C29', 'SGX:5GD', 'SGX:JLB', 'SGX:TCU', 'SGX:P9D', 'SGX:546', 'SGX:P34', 'SGX:H22', 'SGX:ODBU', 'SGX:8AZ', 'SGX:OXMU', 'SGX:F34', 'SGX:K3FD', 'SGX:UD2', 'SGX:NS8U', 'SGX:XZL', 'SGX:MV4', 'SGX:M1GU', 'SGX:NC2', 'SGX:5JS', 'SGX:STG', 'SGX:LJ3', 'SGX:CRPU', 'SGX:8K7', 'SGX:5EN', 'SGX:QNS', 'SGX:K3HD', 'SGX:5IG']\n",
      "Max DD\n",
      "[-64.22764345835105, -64.61538324871003, -69.99999906867743]\n",
      "-69.99999906867743\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- XZL.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TCU.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ODBU.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JLB.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- QNS.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- XJB.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADQU.SI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OXMU.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- 8AZ.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CWBU.SI: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HKB.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STG.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MZH.SI: Data doesn't exist for startDate = 1451595600, endDate = 1546290000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-7-8040e5107bdb>:388: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod()\n",
      "<ipython-input-7-8040e5107bdb>:419: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2019-1-1\n",
      "[49.11992688307967, 34.031798019321634, -8.901456292050778, 23.770800242592877]\n",
      "top_rated_company\n",
      "['SGX:QES', 'SGX:AWX', 'SGX:5G3', 'SGX:C41', 'SGX:CHZ', 'SGX:5WE', 'SGX:UD1U', 'SGX:5DD', 'SGX:1D0', 'SGX:S85', 'SGX:CY6U', 'SGX:S68', 'SGX:H02', 'SGX:N2IU', 'SGX:AGS', 'SGX:S41', 'SGX:OYY', 'SGX:W05', 'SGX:H07', 'SGX:L09', 'SGX:558', 'SGX:5UX', 'SGX:C2PU', 'SGX:RW0U', 'SGX:K3RD', 'SGX:D03', 'SGX:TS0U', 'SGX:AUE', 'SGX:J69U', 'SGX:WJP', 'SGX:OU8', 'SGX:ME8U', 'SGX:O5RU', 'SGX:SK6U', 'SGX:A7RU', 'SGX:G92', 'SGX:BS6', 'SGX:H30', 'SGX:AJBU']\n",
      "low_rated_company\n",
      "['SGX:OXMU', 'SGX:JLB', 'SGX:O10', 'SGX:G41', 'SGX:STG', 'SGX:U10', 'SGX:E5H', 'SGX:579', 'SGX:T24', 'SGX:F99', 'SGX:XZL', 'SGX:P34', 'SGX:TQ5', 'SGX:546', 'SGX:BEC', 'SGX:ODBU', 'SGX:Q01', 'SGX:C6L', 'SGX:J91U', 'SGX:K3FD', 'SGX:MV4', 'SGX:K3HD', 'SGX:U96', 'SGX:N02', 'SGX:BDX', 'SGX:5WH', 'SGX:S51', 'SGX:HMN', 'SGX:E8Z', 'SGX:LJ3', 'SGX:H22', 'SGX:XJB', 'SGX:CWBU', 'SGX:CRPU', 'SGX:F83', 'SGX:QNS', 'SGX:5JS', 'SGX:NS8U', 'SGX:5IG']\n",
      "Max DD\n",
      "[-64.22764345835105, -64.61538324871003, -69.99999906867743, -59.99999720603222]\n",
      "-69.99999906867743\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TCU.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ODBU.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- QNS.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- XJB.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADQU.SI: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- 8AZ.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CWBU.SI: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HKB.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- STG.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MZH.SI: Data doesn't exist for startDate = 1483218000, endDate = 1577826000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n",
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:147: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (4). Possibly due to duplicate points in X.\n",
      "  label = cluster.KMeans(n_clusters=self.n_components, n_init=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8040e5107bdb>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-7-8040e5107bdb>:388: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod()\n",
      "<ipython-input-7-8040e5107bdb>:419: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2020-1-1\n",
      "[49.11992688307967, 34.031798019321634, -8.901456292050778, 23.770800242592877, 1.330804288611202]\n",
      "top_rated_company\n",
      "['SGX:AWX', 'SGX:C41', 'SGX:OYY', 'SGX:1D0', 'SGX:QES', 'SGX:5WE', 'SGX:5WH', 'SGX:5CP', 'SGX:UD1U', 'SGX:CHZ', 'SGX:S68', 'SGX:AGS', 'SGX:N2IU', 'SGX:5G3', 'SGX:5DD', 'SGX:ME8U', 'SGX:H02', 'SGX:CY6U', 'SGX:S85', 'SGX:K3RD', 'SGX:VL6', 'SGX:F03', 'SGX:J91U', 'SGX:A26', 'SGX:J69U', 'SGX:B61', 'SGX:O39', 'SGX:L09', 'SGX:K2LU', 'SGX:BS6', 'SGX:Q5T', 'SGX:OU8', 'SGX:C2PU', 'SGX:A50', 'SGX:M30', 'SGX:E28', 'SGX:TS0U', 'SGX:LJ3', 'SGX:O5RU']\n",
      "low_rated_company\n",
      "['SGX:P34', 'SGX:K3DD', 'SGX:T15', 'SGX:B28', 'SGX:E5H', 'SGX:K3HD', 'SGX:BHK', 'SGX:5JK', 'SGX:BN4', 'SGX:C29', 'SGX:S07', 'SGX:M01', 'SGX:P9D', 'SGX:O10', 'SGX:BDX', 'SGX:5UX', 'SGX:STG', 'SGX:T24', 'SGX:G41', 'SGX:8K7', 'SGX:5EN', 'SGX:U96', 'SGX:K3FD', 'SGX:579', 'SGX:F1E', 'SGX:D03', 'SGX:XZL', 'SGX:NS8U', 'SGX:NC2', 'SGX:F83', 'SGX:OXMU', 'SGX:HMN', 'SGX:C6L', 'SGX:S51', 'SGX:N02', 'SGX:5JS', 'SGX:RE4', 'SGX:ADQU', 'SGX:5IG']\n",
      "Max DD\n",
      "[-64.22764345835105, -64.61538324871003, -69.99999906867743, -59.99999720603222, -108.0525483857059]\n",
      "-108.0525483857059\n"
     ]
    }
   ],
   "source": [
    "# tickers = ['AAPL', 'INTC']\n",
    "\n",
    "yahoo_ticker_list_full = []\n",
    "\n",
    "for tic in tickers:\n",
    "    yahoo_ticker_list_full.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "\n",
    "price_yahoo_main = yf.download(yahoo_ticker_list_full)\n",
    "price_yahoo_main = price_yahoo_main['Adj Close'].fillna(method='backfill')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "years_len = int(cheked_year_end) - int(cheked_year)\n",
    "\n",
    "portfolio_profit_final = []\n",
    "index_profit_final = []\n",
    "max_dd_list = []\n",
    "\n",
    "\n",
    "Percentile_split = .2\n",
    "\n",
    "Winsorize_Threshold = .025\n",
    "\n",
    "# for i in range(years_len):\n",
    "for i in range(years_len):\n",
    "    print('i'*50)\n",
    "    print(i)\n",
    "\n",
    "    df_res = pd.DataFrame()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "\n",
    "            Data_for_Portfolio_tick = Data_for_Portfolio_TOTAL.loc[ticker].fillna(0).iloc[int(cheked_year_end) - (int(cheked_year)-1+i)]\n",
    "#             print(Data_for_Portfolio_tick)\n",
    "            sum_frame = [pd.DataFrame([Data_for_Portfolio_tick]), df_res]\n",
    "            df_res = pd.concat(sum_frame )  \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    Data_for_Portfolio_master_filter = df_res\n",
    "    \n",
    "    yahoo_ticker_list = []\n",
    "\n",
    "    for tic in Data_for_Portfolio_master_filter.index.tolist():\n",
    "        yahoo_ticker_list.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "         \n",
    "\n",
    "   #Winsorize the metric data and compress outliers if desired\n",
    "    Data_for_Portfolio_master_filter['E/P Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['E/P'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['EBITDA/EV Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['EBITDA/EV'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['FCF/P Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['FCF/P'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "\n",
    "    #create Z score to normalize the metrics\n",
    "    Data_for_Portfolio_master_filter['E/P Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['E/P Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['EBITDA/EV Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['EBITDA/EV Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['FCF/P Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['FCF/P Winsorized'])\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Valuation Score'] = \\\n",
    "            Data_for_Portfolio_master_filter['E/P Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['EBITDA/EV Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['FCF/P Z score']\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/P Winsorized']\n",
    "\n",
    "    ###### QUALITY FACTOR ######  \n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/Assets Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['FCF/Assets'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['ROA Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['ROA'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['ROIC Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['ROIC'], \\\n",
    "                                limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Gross Margin Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['GROSS MARGIN'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Current Ratio Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['CURRENT RATIO'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Interest/EBITDA Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['INTEREST/EBITDA'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "\n",
    "    #create Z score\n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/Assets Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['FCF/Assets Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['ROA Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['ROA Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['ROIC Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['ROIC Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Gross Margin Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Gross Margin Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Current Ratio Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Current Ratio Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Interest/EBITDA Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Interest/EBITDA Winsorized'])\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Quality Score'] = \\\n",
    "        Data_for_Portfolio_master_filter['FCF/Assets Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['ROA Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['ROIC Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['Gross Margin Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['Current Ratio Z score']\\\n",
    "            - Data_for_Portfolio_master_filter['Interest/EBITDA Z score']\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    ###### SHAREHOLDER YIELD FACTOR #####\n",
    "\n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['Shareholder Yield'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Shareholder Yield Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Score'] = \\\n",
    "        Data_for_Portfolio_master_filter['Shareholder Yield Z score'] \n",
    "        \n",
    "        \n",
    "        ###### LOW VOLATILITY FACTOR ######\n",
    "\n",
    "    #must have fundamental data from previous factors for price based factors\n",
    "    #as some equities have price data and no fundamental data which should not\n",
    "    #be included\n",
    "\n",
    "    # treasury = 'RGBI.ME'\n",
    "    start = cheked_year\n",
    "    # end = current_date\n",
    "    end =  cheked_year_end\n",
    "\n",
    "#     price_yahoo = yf.download(Data_for_Portfolio_master_filter.index.tolist())\n",
    "    price_yahoo = price_yahoo_main[yahoo_ticker_list]\n",
    "\n",
    "    Sector_stock_returns =  price_yahoo.pct_change()      \n",
    "\n",
    "    #create rolling vol metric for previous 2 years\n",
    "    Sector_stock_rolling_vol = Sector_stock_returns.rolling(252*2).std()\n",
    "\n",
    "    #Choose second to last trading day to look at previous vol   \n",
    "    #Sometimes the dates are off when trying to line up end of quarter and business\n",
    "    #days so to eliminate errors in the for loop I go to day of quarter, shift forward\n",
    "    #a business day and then go back two business days\n",
    "\n",
    "    \n",
    "\n",
    "    Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter_Vol_Signal_Sort = Filter_Vol_Signal.sort_values().dropna() # для цикла паска тикеров\n",
    "\n",
    "    #create z score and rank for the Volatility Factor\n",
    "    # frame = { 'Vol': Filter_Vol_Signal} \n",
    "\n",
    "    # Filter_Vol_Signal_df = pd.DataFrame(frame)\n",
    "    \n",
    "    \n",
    "#     print(pd.DataFrame(stats.zscore(Filter_Vol_Signal)).mean())\n",
    "#     print(pd.DataFrame(stats.zscore(Filter_Vol_Signal)))\n",
    "\n",
    "#     Filter_Vol_Signal = Filter_Vol_Signal.fillna(0)\n",
    "\n",
    "    # Filter_Vol_Signal_df['Vol Z Score'] = stats.zscore(Filter_Vol_Signal) \n",
    "    # Filter_Vol_Signal_df = Filter_Vol_Signal_df.reset_index()\n",
    "    # print(Filter_Vol_Signal_df)\n",
    "\n",
    "    \n",
    "    Data_for_Portfolio_master_filter['Vol Z Score'] = pd.DataFrame(stats.zscore(Filter_Vol_Signal)).fillna(0).mean().tolist()\n",
    "#     print(stats.zscore(Filter_Vol_Signal))\n",
    "    # Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.merge(Filter_Vol_Signal_df, how = 'inner', on = ['ticker']) \n",
    "\n",
    "    \n",
    "    \n",
    "        ###### NEWWWWWWWWWWWWWWWWWWWWWWWWWWWW FACTOR #####\n",
    "   \n",
    "    Data_for_Portfolio_master_filter['Total Equity Grows 5Y Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['Total Equity Grows 5Y'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['EPS without NRI Grows 5Y Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['EPS without NRI Grows 5Y'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Revenue Grows 5Y Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['Revenue Grows 5Y'], \\\n",
    "                                limits=Winsorize_Threshold)\n",
    "\n",
    "\n",
    "    \n",
    "    Data_for_Portfolio_master_filter['Total Equity Grows 5Y Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Total Equity Grows 5Y Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['EPS without NRI Grows 5Y Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['EPS without NRI Grows 5Y Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Revenue Grows 5Y Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Revenue Grows 5Y Winsorized'])\n",
    "    \n",
    "    \n",
    "\n",
    "    Data_for_Portfolio_master_filter['Net Margin % params score'] = np.where(Data_for_Portfolio_master_filter['Net Margin % params'] > 0, 1,0)\n",
    "    \n",
    "    \n",
    "    Data_for_Portfolio_master_filter['Grows score'] = Data_for_Portfolio_master_filter['Net Margin % params score']+ \\\n",
    "                                                    Data_for_Portfolio_master_filter['Total Equity Grows 5Y Z score']+ \\\n",
    "                                                    Data_for_Portfolio_master_filter['EPS without NRI Grows 5Y Z score']+ \\\n",
    "                                                    Data_for_Portfolio_master_filter['Revenue Grows 5Y Z score']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###### TREND FACTOR #####\n",
    "    \n",
    "    total_trend_score = []\n",
    "    \n",
    "    for tic in yahoo_ticker_list:\n",
    "        try:\n",
    "            df = yf.download(tic, str(int(start)+i-2)+'-1-1', str(int(start)+i+1)+'-1-1')\n",
    "        #     print(df)\n",
    "            df = df[['Open', 'High', 'Low', 'Adj Close']]\n",
    "            df['open'] = df['Open'].shift(1)\n",
    "            df['high'] = df['High'].shift(1)\n",
    "            df['low'] = df['Low'].shift(1)\n",
    "            df['close'] = df['Adj Close'].shift(1)\n",
    "\n",
    "            df = df[['open', 'high', 'low', 'close']]\n",
    "            df = df.dropna()\n",
    "\n",
    "            unsup = mix.GaussianMixture(n_components=4,\n",
    "                                        covariance_type=\"spherical\",\n",
    "                                        n_init=100,\n",
    "                                        random_state=42)\n",
    "            unsup.fit(np.reshape(df, (-1, df.shape[1])))\n",
    "            regime = unsup.predict(np.reshape(df, (-1, df.shape[1])))\n",
    "            df['Return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "            Regimes = pd.DataFrame(regime, columns=['Regime'], index=df.index) \\\n",
    "                .join(df, how='inner') \\\n",
    "                .assign(market_cu_return=df.Return.cumsum()) \\\n",
    "                .reset_index(drop=False) \\\n",
    "                .rename(columns={'index': 'Date'})\n",
    "\n",
    "            order = [0, 1, 2, 3]\n",
    "        #     fig = sns.FacetGrid(data=Regimes, hue='Regime', hue_order=order, aspect=2, height=4)\n",
    "        #     fig.map(plt.scatter, 'Date', 'market_cu_return', s=4).add_legend()\n",
    "        #     plt.show()\n",
    "\n",
    "            mean_for_regime = []\n",
    "            cur_price = df['close'][-1]\n",
    "\n",
    "            total_position = 0\n",
    "\n",
    "            for j in order:\n",
    "                mean_for_regime.append(unsup.means_[j][0])\n",
    "    #             print('Mean for regime %i: '%i,unsup.means_[i][0])\n",
    "        #         print('Co-Variance for regime %i: '%i,(unsup.covariances_[i]))\n",
    "\n",
    "            mean_for_regime = np.sort(mean_for_regime)   \n",
    "            for val in  mean_for_regime:\n",
    "                if cur_price > val:\n",
    "                    total_position += 0.25\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            total_trend_score.append(total_position)\n",
    "    #         print(mean_for_regime)\n",
    "    #         print('cur_price')\n",
    "    #         print(cur_price)\n",
    "    #         print('total_position')\n",
    "    #         print(total_position)\n",
    "        except:\n",
    "            total_trend_score.append(0)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Trend Score'] = total_trend_score\n",
    "    \n",
    "    #This is a very simply way to see how much a stock is in a trend up or down\n",
    "    #You could easily make this more complex/robust but it would cost you in \n",
    "    #execution time\n",
    "#     df_sma_50 = price_yahoo.rolling(50).mean()\n",
    "#     df_sma_100 = price_yahoo.rolling(100).mean()\n",
    "#     df_sma_150 = price_yahoo.rolling(150).mean()\n",
    "#     df_sma_200 = price_yahoo.rolling(200).mean()\n",
    "\n",
    "\n",
    "#     Filter_Trend_Signal_50 = df_sma_50[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_100 = df_sma_100[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_150 = df_sma_150[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_200 = df_sma_200[str(int(cheked_year)+i)]\n",
    "\n",
    "#     Price_Signal = price_yahoo[str(int(cheked_year)+i)]\n",
    "\n",
    "#     SMA_all = pd.DataFrame()\n",
    "#     SMA_50 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_50,1,0)).mean()\n",
    "#     SMA_100 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_100,1,0)).mean()\n",
    "#     SMA_150 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_150,1,0)).mean()\n",
    "#     SMA_200 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_200,1,0)).mean()\n",
    "\n",
    "#     SMA_all['SMA_50'] = SMA_50\n",
    "#     SMA_all['SMA_100'] = SMA_100\n",
    "#     SMA_all['SMA_150'] = SMA_150\n",
    "#     SMA_all['SMA_200'] = SMA_200\n",
    "#     SMA_all['Trend Score'] = np.mean(SMA_all, axis=1)\n",
    "\n",
    "#     # print(SMA_all)\n",
    "#     Data_for_Portfolio_master_filter['Trend Score'] = np.mean(SMA_all, axis=1).tolist()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ###### MOMENTUM FACTOR #####\n",
    "\n",
    "#     print('tut')\n",
    "    \n",
    "    # tickers_momentum = list(Sector_stock_prices_vol_df_1_wide.columns)\n",
    "    #from the academic literature of 12 months - 1 month momentum \n",
    "#     df_mom_11_months = price_yahoo[str(int(cheked_year)+i)].pct_change(22*11)\n",
    "#     Data_for_Portfolio_master_filter['Momentum Score'] = pd.DataFrame(stats.zscore(df_mom_11_months.iloc[242:])).fillna(0).mean().tolist()\n",
    "#     # Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.merge(Filter_MOM_df[['ticker','Momentum Score']], how = 'inner', on = ['ticker'])\n",
    "#     Data_for_Portfolio_master_filter\n",
    "\n",
    "\n",
    "\n",
    "    prices = price_yahoo_main[yahoo_ticker_list].asfreq('BM')\n",
    "    prices_yearly_returns = prices.pct_change(12)\n",
    "    prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
    "    Data_for_Portfolio_master_filter['Momentum Score'] = prices_yearly_signal\n",
    "\n",
    "    \n",
    "       \n",
    "    ### Create Composite Score from factors ###\n",
    "\n",
    "    #Because we made all the factors with a z score each factor should have equal\n",
    "    #weight in the composite. You could consider changing the weights based on \n",
    "    #historical statistical significance or whatever else seems reasonable\n",
    "\n",
    "    #This particular scoring system only invests in companies with \n",
    "    #positive trend/momentum after ranking by the other factors\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Total Score'] = Data_for_Portfolio_master_filter['Valuation Score'] +  \\\n",
    "        Data_for_Portfolio_master_filter['Quality Score'] + Data_for_Portfolio_master_filter['Shareholder Yield Score'] +\\\n",
    "        Data_for_Portfolio_master_filter['Momentum Score'] + Data_for_Portfolio_master_filter['Trend Score'] + \\\n",
    "        Data_for_Portfolio_master_filter['Grows score']\n",
    "    \n",
    "    \n",
    "    \n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.sort_values('Total Score', ascending=False)\n",
    "    \n",
    "    top_rated_company = Data_for_Portfolio_master_filter[:int(len(Data_for_Portfolio_master_filter) \\\n",
    "                                                              * Percentile_split)].index.tolist()\n",
    "    top_rated_company\n",
    "\n",
    "    low_rated_company = Data_for_Portfolio_master_filter[-int(len(Data_for_Portfolio_master_filter) \\\n",
    "                                                              * Percentile_split):].index.tolist()\n",
    "    low_rated_company\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    start_hayoo = str(int(start)+i+1)+'-1-1'\n",
    "    end_hayoo = str(int(start)+i+2)+'-1-1'\n",
    "    \n",
    "    cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod()\n",
    "    running_max_BH = np.maximum.accumulate(cum_str_returns_bh[1:].fillna(method='backfill') )\n",
    "    drawdown_BH = (cum_str_returns_bh[1:])/running_max_BH - 1\n",
    "    max_dd = drawdown_BH.min()*100\n",
    "\n",
    "\n",
    "#     try:\n",
    "#         Data_for_Portfolio_master_filter['Max DD'] = max_dd.values \n",
    "#     except:\n",
    "#         Data_for_Portfolio_master_filter['Max DD'] = [max_dd]\n",
    "    \n",
    "    max_dd_list.append(max_dd.min())\n",
    "    \n",
    "#     # == Доходность\n",
    "    \n",
    "    portfolio_profit = [] \n",
    "    profit_list_index = 0\n",
    "\n",
    "    top_rated_company_yahoo = []\n",
    "    low_rated_company_yahoo = []\n",
    "    \n",
    "    \n",
    "    for tic in top_rated_company:\n",
    "        top_rated_company_yahoo.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "        \n",
    "    for tic in low_rated_company:\n",
    "        low_rated_company_yahoo.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "        \n",
    "  \n",
    "    \n",
    "#     profit_yah = yf.download(top_rated_company, start_hayoo, end_hayoo)['Adj Close'].fillna(method='backfill') \n",
    "    profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill') \n",
    "    profit = (profit_yah.iloc[-1]-profit_yah.iloc[0])/profit_yah.iloc[0]\n",
    "    profit = profit.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    portfolio_profit = profit.values.tolist()\n",
    "#     print(profit_yah)\n",
    "            \n",
    "    \n",
    "#     for company in top_rated_company:\n",
    "# #         print('tut1')\n",
    "#         try:\n",
    "#             profit_yah = yf.download(company, start_hayoo, end_hayoo)['Adj Close'].fillna(method='backfill') \n",
    "#             profit = (profit_yah[-1]-profit_yah[0])/profit_yah[0]\n",
    "#             (1 + profit).cumprod()[-1]\n",
    "#             portfolio_profit.append(profit)\n",
    "#             print(profit)\n",
    "#         except:\n",
    "#             pass\n",
    "#     portfolio_profit\n",
    "\n",
    "\n",
    "#     profit_list_index = 0\n",
    "\n",
    "    profit_yah_index = yf.download(index)['Adj Close'].fillna(method='backfill')[str(int(start)+i)] \n",
    "    profit_index = (profit_yah_index[-1]-profit_yah_index[0])/profit_yah_index[0]\n",
    "\n",
    "    \n",
    "\n",
    "    print('Год начальный')\n",
    "    print(start_hayoo)\n",
    "    \n",
    "#     profit_list_index = profit_index\n",
    "\n",
    "    portfolio_profit_final.append(np.mean(portfolio_profit)*100)\n",
    "    index_profit_final.append(profit_index*100)\n",
    "\n",
    "#     returnezzz = pd.DataFrame()\n",
    "#     returnezzz['Portfolio'] = [np.mean(portfolio_profit)*100]\n",
    "#     returnezzz['Index'] = [profit_list_index*100]\n",
    "\n",
    "    print(portfolio_profit_final)\n",
    "\n",
    "    print('top_rated_company')\n",
    "    print(top_rated_company)\n",
    "    print('low_rated_company')\n",
    "    print(low_rated_company)\n",
    "       \n",
    "\n",
    "    print('Max DD')\n",
    "    print(max_dd_list)\n",
    "    print(np.min(max_dd_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Страна</th>\n",
       "      <th>Начало периода</th>\n",
       "      <th>Дходность с ребалансировкой портфеля</th>\n",
       "      <th>Дходность Индекса</th>\n",
       "      <th>Max DD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сингапур</td>\n",
       "      <td>2015</td>\n",
       "      <td>128.357168</td>\n",
       "      <td>24.126498</td>\n",
       "      <td>-108.052548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Страна Начало периода  Дходность с ребалансировкой портфеля  \\\n",
       "0  Сингапур           2015                            128.357168   \n",
       "\n",
       "   Дходность Индекса      Max DD  \n",
       "0          24.126498 -108.052548  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnez_cum_port = pd.DataFrame(portfolio_profit_final).dropna()  \n",
    "returnez_cum_index = pd.DataFrame(index_profit_final).dropna()  \n",
    "\n",
    "returnez = pd.DataFrame()\n",
    "\n",
    "returnez['Страна'] = [LIST]\n",
    "returnez['Начало периода'] = [cheked_year]\n",
    "returnez['Дходность с ребалансировкой портфеля'] = ((1 + (returnez_cum_port/100)).cumprod().iloc[-1]-1)*100\n",
    "returnez['Дходность Индекса'] = ((1 + (returnez_cum_index/100)).cumprod().iloc[-1]-1)*100\n",
    "returnez['Max DD'] = [np.min(max_dd_list)]\n",
    "\n",
    "# gc = gd.service_account(filename='Seetzzz-1cb93f64d8d7.json')\n",
    "# worksheet = gc.open(\"Тесты бэктестинга\").worksheet('Мульти-фактор2')\n",
    "\n",
    "# worksheet.update('A20', [returnez.columns.tolist()] + returnez.values.tolist())\n",
    "\n",
    "returnez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWX.SI     0.709581\n",
       "C41.SI     0.361834\n",
       "OYY.SI     0.579740\n",
       "1D0.SI     0.371609\n",
       "QES.SI    -0.041457\n",
       "5WE.SI    -0.090909\n",
       "5WH.SI    -0.265000\n",
       "5CP.SI    -0.347877\n",
       "UD1U.SI   -0.149523\n",
       "CHZ.SI    -0.071400\n",
       "S68.SI     0.090820\n",
       "AGS.SI     0.059247\n",
       "N2IU.SI   -0.076036\n",
       "5G3.SI    -0.111468\n",
       "5DD.SI     0.438282\n",
       "ME8U.SI    0.147130\n",
       "H02.SI    -0.117722\n",
       "CY6U.SI   -0.062110\n",
       "S85.SI    -0.138951\n",
       "K3RD.SI    0.000000\n",
       "VL6.SI    -0.080855\n",
       "F03.SI     0.012017\n",
       "J91U.SI   -0.209111\n",
       "A26.SI    -0.178839\n",
       "J69U.SI   -0.081118\n",
       "B61.SI    -0.143909\n",
       "O39.SI    -0.026714\n",
       "L09.SI     0.591614\n",
       "K2LU.SI   -0.065435\n",
       "BS6.SI    -0.142444\n",
       "Q5T.SI    -0.150619\n",
       "OU8.SI    -0.209979\n",
       "C2PU.SI    0.195653\n",
       "A50.SI    -0.253731\n",
       "E28.SI     0.482207\n",
       "TS0U.SI   -0.301928\n",
       "LJ3.SI    -0.139333\n",
       "O5RU.SI   -0.077560\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
