{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from pandas_datareader.famafrench import get_available_datasets\n",
    "import pandas_datareader.data as web\n",
    "from yahoo_fin import stock_info as si\n",
    "from performance_analysis import annualized_return\n",
    "from performance_analysis import annualized_standard_deviation\n",
    "from performance_analysis import max_drawdown\n",
    "from performance_analysis import gain_to_pain_ratio\n",
    "from performance_analysis import calmar_ratio\n",
    "from performance_analysis import sharpe_ratio\n",
    "from performance_analysis import sortino_ratio\n",
    "import yfinance as yf\n",
    "import apiclient.discovery\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import httplib2\n",
    "from sklearn import mixture as mix\n",
    "import seaborn as sns \n",
    "import gspread as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISX:BBCA', 'ISX:BBRI', 'ISX:TLKM', 'ISX:BMRI', 'ISX:ARTO', 'ISX:ASII', 'ISX:TPIA', 'ISX:UNVR', 'ISX:EMTK', 'ISX:HMSP', 'ISX:BRPT', 'ISX:CPIN', 'ISX:BRIS', 'ISX:BBNI', 'ISX:ICBP', 'ISX:UNTR', 'ISX:TOWR', 'ISX:SMMA', 'ISX:TBIG', 'ISX:MDKA', 'ISX:GGRM', 'ISX:KLBF', 'ISX:AMRT', 'ISX:ANTM', 'ISX:MEGA', 'ISX:INDF', 'ISX:BNLI', 'ISX:SMGR', 'ISX:INCO', 'ISX:BYAN', 'ISX:MYOR', 'ISX:BANK', 'ISX:AGRO', 'ISX:DNET', 'ISX:ADRO', 'ISX:TCPI', 'ISX:FREN', 'ISX:INTP', 'ISX:INKP', 'ISX:ISAT', 'ISX:MIKA', 'ISX:POLL', 'ISX:SLIS', 'ISX:JSMR', 'ISX:EXCL', 'ISX:BNII', 'ISX:PTBA', 'ISX:ACES', 'ISX:SCMA', 'ISX:PGAS', 'ISX:BNGA', 'ISX:SRTG', 'ISX:BINA', 'ISX:SIDO', 'ISX:MKPI', 'ISX:DMMX', 'ISX:BDMN', 'ISX:BTPN', 'ISX:PWON', 'ISX:NPGF', 'ISX:MASA', 'ISX:CASA', 'ISX:TKIM', 'ISX:BSIM', 'ISX:BBKP', 'ISX:PNBN', 'ISX:BTPS', 'ISX:ITMG', 'ISX:FASW', 'ISX:BSDE', 'ISX:BBSI', 'ISX:AALI', 'ISX:BFIN', 'ISX:NISP', 'ISX:ULTJ', 'ISX:CTRA', 'ISX:MLBI', 'ISX:JPFA', 'ISX:BBTN', 'ISX:SMCB', 'ISX:AKRA', 'ISX:DSSA', 'ISX:KAEF', 'ISX:SILO', 'ISX:HRUM', 'ISX:MAYA', 'ISX:CARE', 'ISX:TAPG', 'ISX:LIFE', 'ISX:BABP', 'ISX:CENT', 'ISX:BJBR', 'ISX:MEDC', 'ISX:CITA', 'ISX:WSKT', 'ISX:LINK', 'ISX:MAPI', 'ISX:TINS', 'ISX:SMAR', 'ISX:MNCN', 'ISX:RMBA', 'ISX:EDGE', 'ISX:TFAS', 'ISX:SMRA', 'ISX:BBYB', 'ISX:BJTM', 'ISX:STTP', 'ISX:BBHI', 'ISX:FAPA', 'ISX:ERAA', 'ISX:IMPC', 'ISX:POWR', 'ISX:APIC', 'ISX:LPKR', 'ISX:IPTV', 'ISX:KRAS', 'ISX:KPIG', 'ISX:ASSA', 'ISX:CMNP', 'ISX:SUPR', 'ISX:DMAS', 'ISX:MCAS', 'ISX:PLIN', 'ISX:NFCX', 'ISX:ROTI', 'ISX:WIKA', 'ISX:LSIP', 'ISX:INDY', 'ISX:SSMS', 'ISX:SAME', 'ISX:SMSM', 'ISX:INPP', 'ISX:ADMF', 'ISX:MLPL', 'ISX:HERO', 'ISX:INAF', 'ISX:PRDA', 'ISX:DMND', 'ISX:BRMS', 'ISX:SIMP', 'ISX:BHIT', 'ISX:MLPT', 'ISX:TURI', 'ISX:IBST', 'ISX:MTDL', 'ISX:TSPC', 'ISX:BOLA', 'ISX:SOHO', 'ISX:TGKA', 'ISX:UCID', 'ISX:JRPT', 'ISX:BBMD', 'ISX:SMBR', 'ISX:ESSA', 'ISX:EPMT', 'ISX:ARNA', 'ISX:MPPA', 'ISX:DUTI', 'ISX:MIDI', 'ISX:BMAS', 'ISX:PNLF', 'ISX:TECH', 'ISX:BKSW', 'ISX:GIAA', 'ISX:FISH', 'ISX:NOBU', 'ISX:SDRA', 'ISX:PTPP', 'ISX:MAPA', 'ISX:DSNG', 'ISX:CLEO', 'ISX:GGRP', 'ISX:LPPF', 'ISX:BOGA', 'ISX:MMLP', 'ISX:AGRS', 'ISX:MSIN', 'ISX:AUTO', 'ISX:WOOD', 'ISX:PNBS', 'ISX:BCAP', 'ISX:MPRO', 'ISX:NATO', 'ISX:BSSR', 'ISX:PSAB', 'ISX:SAMF', 'ISX:BMTR', 'ISX:AGII', 'ISX:PPRO', 'ISX:MYRX', 'ISX:TBLA', 'ISX:ABDA', 'ISX:RALS', 'ISX:DNAR', 'ISX:MBAP', 'ISX:ABMM', 'ISX:MSKY', 'ISX:FAST', 'ISX:TOBA', 'ISX:FILM', 'ISX:PALM', 'ISX:RISE', 'ISX:MARK', 'ISX:BHAT', 'ISX:BUMI', 'ISX:BACA', 'ISX:SRAJ', 'ISX:BEBS', 'ISX:IMAS', 'ISX:KIJA', 'ISX:ZINC', 'ISX:HEAL', 'ISX:AMOR', 'ISX:PBID', 'ISX:SGRO', 'ISX:BKSL', 'ISX:BGTG', 'ISX:WSBP', 'ISX:KINO', 'ISX:NIRO', 'ISX:UNIC', 'ISX:MYOH', 'ISX:BISI', 'ISX:TFCO', 'ISX:ASRI', 'ISX:MPMX', 'ISX:PNIN', 'ISX:BULL', 'ISX:BNBA', 'ISX:HEXA', 'ISX:MAPB', 'ISX:DLTA', 'ISX:DIVA', 'ISX:BESS', 'ISX:SRIL', 'ISX:CPRO', 'ISX:SURE', 'ISX:IMJS', 'ISX:KMTR', 'ISX:PSGO', 'ISX:ASMI', 'ISX:IRRA', 'ISX:CSMI', 'ISX:APLN', 'ISX:MFIN', 'ISX:INPC', 'ISX:INDR', 'ISX:KREN', 'ISX:BUKK', 'ISX:DOID']\n"
     ]
    }
   ],
   "source": [
    "# подключение к гугл таблице\n",
    "\n",
    "LIST = 'Индонезия'\n",
    "\n",
    "index = '^STI'\n",
    "\n",
    "exchange = 'ISX:'\n",
    "\n",
    "exchange_yahoo =  '.JK'\n",
    "\n",
    "# tickers = si.tickers_sp500()\n",
    "cheked_year = '2015' \n",
    "cheked_year_end = '2020' \n",
    "\n",
    "\n",
    "# Файл, полученный в Google Developer Console\n",
    "CREDENTIALS_FILE = 'Seetzzz-1cb93f64d8d7.json'\n",
    "# ID Google Sheets документа (можно взять из его URL)\n",
    "spreadsheet_id = '1lDhu6-tBmoh66a1mY3RU2yPV2_3uIzNSQWNI5UtMcag'\n",
    "spreadsheet_id2 = '1A3leW6ZfsoVEPXZsv0Loj4eAbyKRchnHrJLdP4RIXDA'\n",
    "#\n",
    "# Авторизуемся и получаем service — экземпляр доступа к API\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "    CREDENTIALS_FILE,\n",
    "    ['https://www.googleapis.com/auth/spreadsheets',\n",
    "     'https://www.googleapis.com/auth/drive'])\n",
    "httpAuth = credentials.authorize(httplib2.Http())\n",
    "service = apiclient.discovery.build('sheets', 'v4', http=httpAuth)\n",
    "\n",
    "# ____________________________Парсим тикеры !!!!С ТАБЛИЦЫ!!!! и работаем с ними _______________________________________\n",
    "\n",
    "# Чтения файла\n",
    "values = service.spreadsheets().values().get(\n",
    "    spreadsheetId=spreadsheet_id,\n",
    "    range=f'{LIST}!A1:AA1000',\n",
    "    majorDimension='COLUMNS'\n",
    ").execute()\n",
    "\n",
    "tickers = values['values'][8][2:252]\n",
    "\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Читаем данные из огурцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISX:SMMA\n",
      "ISX:ANTM\n",
      "ISX:BANK\n",
      "ISX:CASA\n",
      "ISX:BBSI\n",
      "ISX:LIFE\n",
      "ISX:TFAS\n",
      "ISX:SOHO\n",
      "ISX:PNLF\n",
      "ISX:TECH\n",
      "ISX:SAMF\n",
      "ISX:ABDA\n",
      "ISX:BHAT\n",
      "ISX:BEBS\n",
      "ISX:AMOR\n",
      "ISX:PNIN\n",
      "ISX:BESS\n",
      "ISX:ASMI\n",
      "ISX:IRRA\n",
      "ISX:CSMI\n"
     ]
    }
   ],
   "source": [
    "# # ['annuals']\n",
    "\n",
    "Data_for_Portfolio_TOTAL = pd.DataFrame()\n",
    " \n",
    "for ticker in tickers:\n",
    "    with open(f'''BANKA/data_json_{ticker.replace(exchange, '')}.pickle''', 'rb') as f:\n",
    "        data_json = pickle.load(f)\n",
    "\n",
    "    with open(f'''BANKA/data_json_keyratios_{ticker.replace(exchange, '')}.pickle''', 'rb') as f:\n",
    "        data_json_keyratios = pickle.load(f)\n",
    "\n",
    "#     print(data_json)    \n",
    "    try:\n",
    "        date_list = pd.Series(data_json['financials']['annuals']['Fiscal Year'])\n",
    "        keyratios = pd.DataFrame(data_json_keyratios['Fundamental'], index=[0]) \n",
    "        income_df = pd.DataFrame(data_json['financials']['annuals']['income_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('', 0).replace('N/A', 0).astype(float)\n",
    "        balance_df = pd.DataFrame(data_json['financials']['annuals']['balance_sheet']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        cashflow_df = pd.DataFrame(data_json['financials']['annuals']['cashflow_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        valuation_ratios_df = pd.DataFrame(data_json['financials']['annuals']['valuation_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        valuation_and_quality_df = pd.DataFrame(data_json['financials']['annuals']['valuation_and_quality']).set_index(date_list).drop(['Restated Filing Date', 'Filing Date', 'Earnings Release Date'], axis=1).replace('', 0).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        common_size_ratios_df = pd.DataFrame(data_json['financials']['annuals']['common_size_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).replace('Negative Tangible Equity', 0).astype(float)\n",
    "        # per_share_data_array_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        per_share_data_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('', 0).replace('No Debt', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        \n",
    "        check = 1\n",
    "    except:\n",
    "        check = 0\n",
    "        print(ticker)\n",
    "        \n",
    "        pass\n",
    "            \n",
    "    if check == 1:\n",
    "    \n",
    "        try:\n",
    "\n",
    "            Data_for_Portfolio = pd.DataFrame()\n",
    "        #     \n",
    "            Data_for_Portfolio['E/P'] = income_df['Net Income'] / valuation_and_quality_df['Market Cap'] \n",
    "            # income_df['Net Income']\n",
    "            # valuation_and_quality_df.replace('-', 0)\n",
    "\n",
    "\n",
    "    #             Data_for_Portfolio['EBITDA/EV'] = income_df['EBITDA'] / (valuation_and_quality_df['Enterprise Value ($M)']*1000000)\n",
    "            try:\n",
    "                Data_for_Portfolio['EBITDA/EV'] = 1/valuation_ratios_df['EV-to-EBITDA']\n",
    "            except:\n",
    "                Data_for_Portfolio['EBITDA/EV'] = income_df['Pretax Income'] / valuation_and_quality_df['Enterprise Value ($M)']\n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['ncfcommon'] = cashflow_df['Free Cash Flow']/(valuation_and_quality_df['Shares Outstanding (EOP)']**1000)\n",
    "\n",
    "    #             try:    \n",
    "    #                 Data_for_Portfolio['Total Debt'] = (balance_df['Short-Term Debt'] + balance_df['Long-Term Debt'])\n",
    "            Data_for_Portfolio['Total Debt'] =per_share_data_df['Total Debt per Share']*(valuation_and_quality_df['Shares Outstanding (EOP)']*1000)\n",
    "    #             except:\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['Shareholder Yield'] = -((Data_for_Portfolio['Total Debt'] + cashflow_df['Free Cash Flow'] \\\n",
    "                                             + Data_for_Portfolio['ncfcommon']) / valuation_and_quality_df['Market Cap'])\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['FCF/P'] = cashflow_df['Free Cash Flow'] / valuation_and_quality_df['Market Cap']\n",
    "            Data_for_Portfolio\n",
    "            # Data_for_Portfolio['Shareholder Yield'] \n",
    "            Data_for_Portfolio['Book Value per Share'] = per_share_data_df['Book Value per Share']\n",
    "            Data_for_Portfolio['Dividends per Share'] =per_share_data_df['Dividends per Share'] \n",
    "            Data_for_Portfolio['Dividend Payout Ratio'] =common_size_ratios_df['Dividend Payout Ratio']\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Current Assets']\n",
    "            except:\n",
    "                Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / (balance_df['Balance Statement Cash and cash equivalents'] + balance_df['Accounts Receivable'])                                   \n",
    "\n",
    "            #Can you generate returns on investment?   \n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['ROA'] = common_size_ratios_df['ROA %']  \n",
    "            Data_for_Portfolio['ROIC'] = common_size_ratios_df['ROIC %']\n",
    "            #Do you have a defendable business model?\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Gross Margin %']\n",
    "\n",
    "            except:\n",
    "                Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Net Interest Margin (Bank Only) %']\n",
    "\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['CURRENT RATIO'] = valuation_and_quality_df['Current Ratio'] \n",
    "            except:\n",
    "                Data_for_Portfolio['CURRENT RATIO'] = 1/common_size_ratios_df['Debt-to-Equity']\n",
    "\n",
    "            try:\n",
    "                Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['EBITDA']\n",
    "            except:\n",
    "                Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['Pretax Income']\n",
    "\n",
    "                \n",
    "   \n",
    "                \n",
    "    # balance_df['Total Equity']\n",
    "    # per_share_data_df['EPS without NRI']\n",
    "    # income_df['Revenue']\n",
    "    # income_df['Net Margin %']\n",
    "\n",
    "#             total_equity_grows_list = []\n",
    "#             EPS_grows_list = []\n",
    "#             rvenue_grows_list = []\n",
    "\n",
    "#         #  (500-400)/400*100=25%\n",
    "\n",
    "\n",
    "#             total_equity_grows_list.append(0)\n",
    "#             EPS_grows_list.append(0)\n",
    "#             rvenue_grows_list.append(0)\n",
    "\n",
    "#             for year in range(len(Data_for_Portfolio)):\n",
    "\n",
    "#                 try:\n",
    "#                     total_equity_grows_list.append((balance_df['Total Equity'][year+1] - balance_df['Total Equity'][year])/ balance_df['Total Equity'][year]*100)\n",
    "#                 except:\n",
    "#                     pass\n",
    "#                 try:\n",
    "#                     EPS_grows_list.append((per_share_data_df['EPS without NRI'][year+1] - per_share_data_df['EPS without NRI'][year])/ per_share_data_df['EPS without NRI'][year]*100)\n",
    "#                 except:\n",
    "#                     pass\n",
    "#                 try:\n",
    "#                     rvenue_grows_list.append((income_df['Revenue'][year+1] - income_df['Revenue'][year])/ income_df['Revenue'][year]*100)\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "#             mean_total_equity_grows_list = [0, 0, 0, 0]\n",
    "#             mean_EPS_grows_list = [0, 0, 0, 0]\n",
    "#             mean_rvenue_grows_list = [0, 0, 0, 0]\n",
    "#             margin_params_list = [0, 0, 0, 0]\n",
    "\n",
    "#             for yearzz in range(len(Data_for_Portfolio)):\n",
    "#                 if len(total_equity_grows_list[yearzz:5+yearzz])  == 5:\n",
    "#                     mean_total_equity_grows_list.append(np.mean(total_equity_grows_list[yearzz:5+yearzz]))\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "#                 if len(EPS_grows_list[yearzz:5+yearzz])  == 5:\n",
    "#                     mean_EPS_grows_list.append(np.mean(EPS_grows_list[yearzz:5+yearzz]))\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "#                 if len(rvenue_grows_list[yearzz:5+yearzz])  == 5:\n",
    "#                     mean_rvenue_grows_list.append(np.mean(rvenue_grows_list[yearzz:5+yearzz]))\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "#             Data_for_Portfolio['Net Margin %'] = income_df['Net Margin %']   \n",
    "\n",
    "\n",
    "#             for k in range(len(Data_for_Portfolio)):\n",
    "#     #             print(len(Data_for_Portfolio['Net Margin %'][k:5+k]))\n",
    "#                 if len(Data_for_Portfolio['Net Margin %'][k:5+k])  == 5:\n",
    "#                     Y = Data_for_Portfolio['Net Margin %'][k:5+k].astype(float)\n",
    "#                     X = list(range(len(date_list[k:5+k])))\n",
    "#                     # X = sm.add_constant(X)\n",
    "#                     model = sm.OLS(Y,X)\n",
    "#                     results = model.fit()\n",
    "#                     margin_params_list.append(results.params[0])\n",
    "#     #                 print(results.params[0])\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "#     #         print(margin_params_list)\n",
    "#     #         print(Data_for_Portfolio['Net Margin %'])\n",
    "\n",
    "#             Data_for_Portfolio['Total Equity Grows 5Y'] = mean_total_equity_grows_list\n",
    "#             Data_for_Portfolio['EPS without NRI Grows 5Y'] = mean_EPS_grows_list\n",
    "#             Data_for_Portfolio['Revenue Grows 5Y'] = mean_rvenue_grows_list\n",
    "#             Data_for_Portfolio['Net Margin % params'] = margin_params_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     #             Дмитрий 9:27\n",
    "#     #         Data_for_Portfolio_master_filter['Shareholder Yield Score'] = \n",
    "\n",
    "#     #    Показатель Балансовая стоимость (чем больше, тем лучше)   +\n",
    "#     #     \"Book Value per Share\" находится в \"per_share_data_array\":\n",
    "\n",
    "#     #    Показатель Див доходности (чем больше, тем лучше) +\n",
    "#     #  \t\"Dividend Yield %\" находится в \"valuation_ratios\": + \"Buyback Yield %\" находится в \"valuation_ratios\":\n",
    "\n",
    "#     #    Показатель PayOut Ratio (чем меньше, тем лучше)  +\n",
    "#     #     \"Dividend Payout Ratio\" находится в \"common_size_ratios\":\n",
    "\n",
    "#             Data_for_Portfolio['Div Yield'] = valuation_and_quality_df['Buyback Yield %'] + valuation_ratios_df['Dividend Yield %']\n",
    "\n",
    "#             div_yield_list = [0]\n",
    "#             book_value_per_share_list = [0]\n",
    "#             dividend_payout_ratio_list = [0]\n",
    "\n",
    "#         #  (500-400)/400*100=25%\n",
    "\n",
    "#             for year_div in range(len(Data_for_Portfolio)):\n",
    "\n",
    "#                 try:\n",
    "#                     div_yield_list.append((Data_for_Portfolio['Div Yield'][year_div+1] - Data_for_Portfolio['Div Yield'][year_div])/ Data_for_Portfolio['Div Yield'][year_div]*100)\n",
    "#                 except:\n",
    "#                     pass\n",
    "#                 try:\n",
    "#                     book_value_per_share_list.append((per_share_data_df['Book Value per Share'][year_div+1] - per_share_data_df['Book Value per Share'][year_div])/ per_share_data_df['Book Value per Share'][year_div]*100)\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "#                 try:\n",
    "#                     dividend_payout_ratio_list.append((common_size_ratios_df['Dividend Payout Ratio'][year_div+1] - common_size_ratios_df['Dividend Payout Ratio'][year_div])/ common_size_ratios_df['Dividend Payout Ratio'][year_div]*100)\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "\n",
    "#             div_yield_list_5y = [0, 0, 0, 0, 0]\n",
    "#             book_value_per_share_list_5y = [0, 0, 0, 0, 0]\n",
    "#             dividend_payout_ratio_list_5y = [0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "#             for year_div_5 in range(len(Data_for_Portfolio)):\n",
    "#                 if len(total_equity_grows_list[year_div_5:5+year_div_5])  == 5:\n",
    "#                     mean_total_equity_grows_list.append(np.mean(total_equity_grows_list[year_div_5:5+year_div_5]))\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "#                 if len(EPS_grows_list[year_div_5:5+year_div_5])  == 5:\n",
    "#                     mean_EPS_grows_list.append(np.mean(EPS_grows_list[year_div_5:5+year_div_5]))\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "#                 if len(rvenue_grows_list[year_div_5:5+year_div_5])  == 5:\n",
    "#                     mean_rvenue_grows_list.append(np.mean(dividend_payout_ratio_list[year_div_5:5+year_div_5]))\n",
    "#                 else:\n",
    "#                     pass\n",
    "\n",
    "\n",
    "#             Data_for_Portfolio['Book Value per Share 5Y'] = book_value_per_share_list\n",
    "#             Data_for_Portfolio['Div Yield 5Y'] = div_yield_list\n",
    "#             Data_for_Portfolio['Dividend Payout Ratio 5Y'] = dividend_payout_ratio_list\n",
    "\n",
    "\n",
    "\n",
    "#     #             regression = pd.ols(y=Data_for_Portfolio['Net Margin %'], x=date_list)\n",
    "#     #             print(regression.summary)\n",
    "\n",
    "#     #             Data_for_Portfolio['Total Equity Grows'] = total_equity_grows_list\n",
    "#     #             Data_for_Portfolio['EPS without NRI Grows'] = EPS_grows_list\n",
    "#     #             Data_for_Portfolio['Revenue Grows'] = rvenue_grows_list\n",
    "#     #             Data_for_Portfolio['Net Margin %'] = income_df['Net Margin %']\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['Company'] = ticker\n",
    "            Data_for_Portfolio['Date'] = list(date_list)\n",
    "\n",
    "            Data_for_Portfolio = Data_for_Portfolio.replace([np.inf, -np.inf], 0)\n",
    "            Data_for_Portfolio = Data_for_Portfolio.set_index('Company')\n",
    "            Data_for_Portfolio = Data_for_Portfolio[::-1].fillna(0)\n",
    "\n",
    "            sumz_frame= [Data_for_Portfolio, Data_for_Portfolio_TOTAL]\n",
    "            Data_for_Portfolio_TOTAL = pd.concat(sumz_frame)\n",
    "\n",
    "        except:\n",
    "            print(ticker)\n",
    "            pass\n",
    "\n",
    "#         print(list(date_list))\n",
    "# list(set(Data_for_Portfolio_TOTAL.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(Data_for_Portfolio_TOTAL.index.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(Data_for_Portfolio_TOTAL.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ['annuals']\n",
    "\n",
    "# tickers = si.tickers_sp500()\n",
    "\n",
    "# Data_for_Portfolio_TOTAL = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# for ticker in tickers:\n",
    "#     with open(f'BANKA/data_json_{ticker}.pickle', 'rb') as f:\n",
    "#         data_json = pickle.load(f)\n",
    "\n",
    "#     with open(f'BANKA/data_json_keyratios_{ticker}.pickle', 'rb') as f:\n",
    "#         data_json_keyratios = pickle.load(f)\n",
    "\n",
    "# #     print(data_json)    \n",
    "#     try:\n",
    "#         date_list = pd.Series(data_json['financials']['annuals']['Fiscal Year'])\n",
    "#         keyratios = pd.DataFrame(data_json_keyratios['Fundamental'], index=[0]) \n",
    "#         income_df = pd.DataFrame(data_json['financials']['annuals']['income_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('', 0).replace('N/A', 0).astype(float)\n",
    "#         balance_df = pd.DataFrame(data_json['financials']['annuals']['balance_sheet']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         cashflow_df = pd.DataFrame(data_json['financials']['annuals']['cashflow_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         valuation_ratios_df = pd.DataFrame(data_json['financials']['annuals']['valuation_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         valuation_and_quality_df = pd.DataFrame(data_json['financials']['annuals']['valuation_and_quality']).set_index(date_list).drop(['Restated Filing Date', 'Filing Date', 'Earnings Release Date'], axis=1).replace('', 0).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         common_size_ratios_df = pd.DataFrame(data_json['financials']['annuals']['common_size_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).replace('Negative Tangible Equity', 0).astype(float)\n",
    "#         # per_share_data_array_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         per_share_data_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('', 0).replace('No Debt', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        \n",
    "#         check = 1\n",
    "#     except:\n",
    "#         pass\n",
    "            \n",
    "#     if check == 1:\n",
    "    \n",
    "#         Data_for_Portfolio = pd.DataFrame()\n",
    "#     #     \n",
    "#         Data_for_Portfolio['E/P'] = income_df['Net Income'] / valuation_and_quality_df['Market Cap'] \n",
    "#         # income_df['Net Income']\n",
    "#         # valuation_and_quality_df.replace('-', 0)\n",
    "#         Data_for_Portfolio\n",
    "#         try:\n",
    "#             Data_for_Portfolio['EBITDA/EV'] = income_df['EBITDA'] / (valuation_and_quality_df['Enterprise Value ($M)']*1000000)\n",
    "#         except:\n",
    "#             Data_for_Portfolio['EBITDA/EV'] = Data_for_Portfolio['E/P'] * 0\n",
    "\n",
    "#         Data_for_Portfolio['ncfcommon'] = cashflow_df['Free Cash Flow']/valuation_and_quality_df['Shares Outstanding (EOP)']\n",
    "#         try:\n",
    "#             Data_for_Portfolio['Total Debt'] = (balance_df['Short-Term Debt'] + balance_df['Long-Term Debt'])\n",
    "#         except:\n",
    "#             Data_for_Portfolio['Total Debt'] = Data_for_Portfolio['ncfcommon'] * 0\n",
    "# #             print(Data_for_Portfolio)\n",
    "\n",
    "#         Data_for_Portfolio['Shareholder Yield'] = -((Data_for_Portfolio['Total Debt'] + cashflow_df['Free Cash Flow'] \\\n",
    "#                                          + Data_for_Portfolio['ncfcommon']) / valuation_and_quality_df['Market Cap'])\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['FCF/P'] = cashflow_df['Free Cash Flow'] / valuation_and_quality_df['Market Cap']\n",
    "#         Data_for_Portfolio\n",
    "#         # Data_for_Portfolio['Shareholder Yield'] \n",
    "#         Data_for_Portfolio['Book Value per Share'] = per_share_data_df['Book Value per Share']\n",
    "#         Data_for_Portfolio['Dividends per Share'] =per_share_data_df['Dividends per Share'] \n",
    "#         Data_for_Portfolio['Dividend Payout Ratio'] =common_size_ratios_df['Dividend Payout Ratio']\n",
    "\n",
    "#         try:\n",
    "#             Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Current Assets']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Assets']\n",
    "#         #Can you generate returns on investment?   \n",
    "\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['ROA'] = common_size_ratios_df['ROA %']  \n",
    "#         Data_for_Portfolio['ROIC'] = common_size_ratios_df['ROIC %']\n",
    "#         #Do you have a defendable business model?\n",
    "#         try:\n",
    "#             Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Gross Margin %']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['GROSS MARGIN'] = Data_for_Portfolio['ROA'] * 0\n",
    "#         #Current Financial Strength\n",
    "#         try:\n",
    "#             Data_for_Portfolio['CURRENT RATIO'] = balance_df['Total Current Assets'] / balance_df['Total Current Liabilities']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['CURRENT RATIO'] = balance_df['Total Assets'] / balance_df['Total Liabilities']\n",
    "\n",
    "\n",
    "#         try:\n",
    "#             Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['EBITDA']\n",
    "#         except:\n",
    "#             try:\n",
    "#                 Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense (Positive)'] / income_df['EBITDA']\n",
    "#             except:\n",
    "#                 Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['Company'] = ticker\n",
    "#         Data_for_Portfolio['Date'] = list(date_list)\n",
    "\n",
    "#         Data_for_Portfolio = Data_for_Portfolio.replace([np.inf, -np.inf], 0)\n",
    "#         Data_for_Portfolio = Data_for_Portfolio.set_index('Company')\n",
    "#         Data_for_Portfolio = Data_for_Portfolio[::-1]\n",
    "\n",
    "#         sumz_frame= [Data_for_Portfolio, Data_for_Portfolio_TOTAL]\n",
    "#         Data_for_Portfolio_TOTAL = pd.concat(sumz_frame)\n",
    "\n",
    "\n",
    "\n",
    "# #         print(list(date_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  250 of 250 completed\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SURE.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DIVA.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MAPB.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WSBP.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BGTG.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PBID.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HEAL.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ZINC.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MARK.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FILM.JK: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-375700073681>:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['open'] = df['Open'].shift(1)\n",
      "Exception in thread Thread-302:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\connection.py\", line 169, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\util\\connection.py\", line 96, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\util\\connection.py\", line 86, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1010, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\connection.py\", line 353, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\connection.py\", line 181, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x0000024722F1FFD0>: Failed to establish a new connection: [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Max retries exceeded with url: /v8/finance/chart/RALS.JK?period1=1356987600&period2=1451595600&interval=1d&includePrePost=False&events=div%2Csplits (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000024722F1FFD0>: Failed to establish a new connection: [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\multitasking\\__init__.py\", line 102, in _run_via_pool\n",
      "    return callee(*args, **kwargs)\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\yfinance\\multi.py\", line 169, in _download_one_threaded\n",
      "    data = _download_one(ticker, start, end, auto_adjust, back_adjust,\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\yfinance\\multi.py\", line 181, in _download_one\n",
      "    return Ticker(ticker).history(period=period, interval=interval,\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\yfinance\\base.py\", line 152, in history\n",
      "    data = self.session.get(\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\requests\\api.py\", line 76, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\requests\\api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\requests\\sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\requests\\sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\Anton\\anaconda\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Max retries exceeded with url: /v8/finance/chart/RALS.JK?period1=1356987600&period2=1451595600&interval=1d&includePrePost=False&events=div%2Csplits (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000024722F1FFD0>: Failed to establish a new connection: [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера'))\n"
     ]
    }
   ],
   "source": [
    "# tickers = ['AAPL', 'INTC']\n",
    "\n",
    "yahoo_ticker_list_full = []\n",
    "\n",
    "for tic in tickers:\n",
    "    yahoo_ticker_list_full.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "\n",
    "price_yahoo_main = yf.download(yahoo_ticker_list_full)\n",
    "price_yahoo_main = price_yahoo_main['Adj Close'].fillna(method='backfill')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "years_len = int(cheked_year_end) - int(cheked_year)\n",
    "\n",
    "portfolio_profit_final = []\n",
    "index_profit_final = []\n",
    "max_dd_list = []\n",
    "\n",
    "\n",
    "Percentile_split = .2\n",
    "\n",
    "Winsorize_Threshold = .025\n",
    "\n",
    "# for i in range(years_len):\n",
    "for i in range(years_len):\n",
    "    print('i'*50)\n",
    "    print(i)\n",
    "\n",
    "    df_res = pd.DataFrame()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "\n",
    "            Data_for_Portfolio_tick = Data_for_Portfolio_TOTAL.loc[ticker].fillna(0).iloc[int(cheked_year_end) - (int(cheked_year)-1+i)]\n",
    "#             print(Data_for_Portfolio_tick)\n",
    "            sum_frame = [pd.DataFrame([Data_for_Portfolio_tick]), df_res]\n",
    "            df_res = pd.concat(sum_frame )  \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    Data_for_Portfolio_master_filter = df_res\n",
    "    \n",
    "    yahoo_ticker_list = []\n",
    "\n",
    "    for tic in Data_for_Portfolio_master_filter.index.tolist():\n",
    "        yahoo_ticker_list.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "         \n",
    "\n",
    "   #Winsorize the metric data and compress outliers if desired\n",
    "    Data_for_Portfolio_master_filter['E/P Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['E/P'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['EBITDA/EV Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['EBITDA/EV'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['FCF/P Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['FCF/P'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "\n",
    "    #create Z score to normalize the metrics\n",
    "    Data_for_Portfolio_master_filter['E/P Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['E/P Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['EBITDA/EV Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['EBITDA/EV Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['FCF/P Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['FCF/P Winsorized'])\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Valuation Score'] = \\\n",
    "            Data_for_Portfolio_master_filter['E/P Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['EBITDA/EV Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['FCF/P Z score']\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/P Winsorized']\n",
    "\n",
    "    ###### QUALITY FACTOR ######  \n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/Assets Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['FCF/Assets'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['ROA Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['ROA'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['ROIC Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['ROIC'], \\\n",
    "                                limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Gross Margin Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['GROSS MARGIN'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Current Ratio Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['CURRENT RATIO'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Interest/EBITDA Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['INTEREST/EBITDA'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "\n",
    "    #create Z score\n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/Assets Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['FCF/Assets Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['ROA Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['ROA Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['ROIC Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['ROIC Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Gross Margin Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Gross Margin Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Current Ratio Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Current Ratio Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Interest/EBITDA Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Interest/EBITDA Winsorized'])\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Quality Score'] = \\\n",
    "        Data_for_Portfolio_master_filter['FCF/Assets Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['ROA Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['ROIC Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['Gross Margin Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['Current Ratio Z score']\\\n",
    "            - Data_for_Portfolio_master_filter['Interest/EBITDA Z score']\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    ###### SHAREHOLDER YIELD FACTOR #####\n",
    "\n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['Shareholder Yield'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Shareholder Yield Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Score'] = \\\n",
    "        Data_for_Portfolio_master_filter['Shareholder Yield Z score'] \n",
    "        \n",
    "        \n",
    "        ###### LOW VOLATILITY FACTOR ######\n",
    "\n",
    "    #must have fundamental data from previous factors for price based factors\n",
    "    #as some equities have price data and no fundamental data which should not\n",
    "    #be included\n",
    "\n",
    "    # treasury = 'RGBI.ME'\n",
    "    start = cheked_year\n",
    "    # end = current_date\n",
    "    end =  cheked_year_end\n",
    "\n",
    "#     price_yahoo = yf.download(Data_for_Portfolio_master_filter.index.tolist())\n",
    "    price_yahoo = price_yahoo_main[yahoo_ticker_list]\n",
    "\n",
    "    Sector_stock_returns =  price_yahoo.pct_change()      \n",
    "\n",
    "    #create rolling vol metric for previous 2 years\n",
    "    Sector_stock_rolling_vol = Sector_stock_returns.rolling(252*2).std()\n",
    "\n",
    "    #Choose second to last trading day to look at previous vol   \n",
    "    #Sometimes the dates are off when trying to line up end of quarter and business\n",
    "    #days so to eliminate errors in the for loop I go to day of quarter, shift forward\n",
    "    #a business day and then go back two business days\n",
    "\n",
    "    \n",
    "\n",
    "    Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter_Vol_Signal_Sort = Filter_Vol_Signal.sort_values().dropna() # для цикла паска тикеров\n",
    "\n",
    "    #create z score and rank for the Volatility Factor\n",
    "    # frame = { 'Vol': Filter_Vol_Signal} \n",
    "\n",
    "    # Filter_Vol_Signal_df = pd.DataFrame(frame)\n",
    "    \n",
    "    \n",
    "#     print(pd.DataFrame(stats.zscore(Filter_Vol_Signal)).mean())\n",
    "#     print(pd.DataFrame(stats.zscore(Filter_Vol_Signal)))\n",
    "\n",
    "#     Filter_Vol_Signal = Filter_Vol_Signal.fillna(0)\n",
    "\n",
    "    # Filter_Vol_Signal_df['Vol Z Score'] = stats.zscore(Filter_Vol_Signal) \n",
    "    # Filter_Vol_Signal_df = Filter_Vol_Signal_df.reset_index()\n",
    "    # print(Filter_Vol_Signal_df)\n",
    "\n",
    "    \n",
    "    Data_for_Portfolio_master_filter['Vol Z Score'] = pd.DataFrame(stats.zscore(Filter_Vol_Signal)).fillna(0).mean().tolist()\n",
    "#     print(stats.zscore(Filter_Vol_Signal))\n",
    "    # Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.merge(Filter_Vol_Signal_df, how = 'inner', on = ['ticker']) \n",
    "\n",
    "    ###### TREND FACTOR #####\n",
    "    \n",
    "    total_trend_score = []\n",
    "    \n",
    "    for tic in yahoo_ticker_list:\n",
    "        try:\n",
    "            df = yf.download(tic, str(int(start)+i-2)+'-1-1', str(int(start)+i+1)+'-1-1')\n",
    "        #     print(df)\n",
    "            df = df[['Open', 'High', 'Low', 'Adj Close']]\n",
    "            df['open'] = df['Open'].shift(1)\n",
    "            df['high'] = df['High'].shift(1)\n",
    "            df['low'] = df['Low'].shift(1)\n",
    "            df['close'] = df['Adj Close'].shift(1)\n",
    "\n",
    "            df = df[['open', 'high', 'low', 'close']]\n",
    "            df = df.dropna()\n",
    "\n",
    "            unsup = mix.GaussianMixture(n_components=4,\n",
    "                                        covariance_type=\"spherical\",\n",
    "                                        n_init=100,\n",
    "                                        random_state=42)\n",
    "            unsup.fit(np.reshape(df, (-1, df.shape[1])))\n",
    "            regime = unsup.predict(np.reshape(df, (-1, df.shape[1])))\n",
    "            df['Return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "            Regimes = pd.DataFrame(regime, columns=['Regime'], index=df.index) \\\n",
    "                .join(df, how='inner') \\\n",
    "                .assign(market_cu_return=df.Return.cumsum()) \\\n",
    "                .reset_index(drop=False) \\\n",
    "                .rename(columns={'index': 'Date'})\n",
    "\n",
    "            order = [0, 1, 2, 3]\n",
    "        #     fig = sns.FacetGrid(data=Regimes, hue='Regime', hue_order=order, aspect=2, height=4)\n",
    "        #     fig.map(plt.scatter, 'Date', 'market_cu_return', s=4).add_legend()\n",
    "        #     plt.show()\n",
    "\n",
    "            mean_for_regime = []\n",
    "            cur_price = df['close'][-1]\n",
    "\n",
    "            total_position = 0\n",
    "\n",
    "            for j in order:\n",
    "                mean_for_regime.append(unsup.means_[j][0])\n",
    "    #             print('Mean for regime %i: '%i,unsup.means_[i][0])\n",
    "        #         print('Co-Variance for regime %i: '%i,(unsup.covariances_[i]))\n",
    "\n",
    "            mean_for_regime = np.sort(mean_for_regime)   \n",
    "            for val in  mean_for_regime:\n",
    "                if cur_price > val:\n",
    "                    total_position += 0.25\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            total_trend_score.append(total_position)\n",
    "    #         print(mean_for_regime)\n",
    "    #         print('cur_price')\n",
    "    #         print(cur_price)\n",
    "    #         print('total_position')\n",
    "    #         print(total_position)\n",
    "        except:\n",
    "            total_trend_score.append(0)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Trend Score'] = total_trend_score\n",
    "    \n",
    "    #This is a very simply way to see how much a stock is in a trend up or down\n",
    "    #You could easily make this more complex/robust but it would cost you in \n",
    "    #execution time\n",
    "#     df_sma_50 = price_yahoo.rolling(50).mean()\n",
    "#     df_sma_100 = price_yahoo.rolling(100).mean()\n",
    "#     df_sma_150 = price_yahoo.rolling(150).mean()\n",
    "#     df_sma_200 = price_yahoo.rolling(200).mean()\n",
    "\n",
    "\n",
    "#     Filter_Trend_Signal_50 = df_sma_50[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_100 = df_sma_100[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_150 = df_sma_150[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_200 = df_sma_200[str(int(cheked_year)+i)]\n",
    "\n",
    "#     Price_Signal = price_yahoo[str(int(cheked_year)+i)]\n",
    "\n",
    "#     SMA_all = pd.DataFrame()\n",
    "#     SMA_50 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_50,1,0)).mean()\n",
    "#     SMA_100 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_100,1,0)).mean()\n",
    "#     SMA_150 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_150,1,0)).mean()\n",
    "#     SMA_200 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_200,1,0)).mean()\n",
    "\n",
    "#     SMA_all['SMA_50'] = SMA_50\n",
    "#     SMA_all['SMA_100'] = SMA_100\n",
    "#     SMA_all['SMA_150'] = SMA_150\n",
    "#     SMA_all['SMA_200'] = SMA_200\n",
    "#     SMA_all['Trend Score'] = np.mean(SMA_all, axis=1)\n",
    "\n",
    "#     # print(SMA_all)\n",
    "#     Data_for_Portfolio_master_filter['Trend Score'] = np.mean(SMA_all, axis=1).tolist()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ###### MOMENTUM FACTOR #####\n",
    "\n",
    "#     print('tut')\n",
    "    \n",
    "    # tickers_momentum = list(Sector_stock_prices_vol_df_1_wide.columns)\n",
    "    #from the academic literature of 12 months - 1 month momentum \n",
    "#     df_mom_11_months = price_yahoo[str(int(cheked_year)+i)].pct_change(22*11)\n",
    "#     Data_for_Portfolio_master_filter['Momentum Score'] = pd.DataFrame(stats.zscore(df_mom_11_months.iloc[242:])).fillna(0).mean().tolist()\n",
    "#     # Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.merge(Filter_MOM_df[['ticker','Momentum Score']], how = 'inner', on = ['ticker'])\n",
    "#     Data_for_Portfolio_master_filter\n",
    "\n",
    "\n",
    "\n",
    "    prices = price_yahoo_main[yahoo_ticker_list].asfreq('BM')\n",
    "    prices_yearly_returns = prices.pct_change(12)\n",
    "    prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
    "    Data_for_Portfolio_master_filter['Momentum Score'] = prices_yearly_signal\n",
    "\n",
    "    \n",
    "       \n",
    "    ### Create Composite Score from factors ###\n",
    "\n",
    "    #Because we made all the factors with a z score each factor should have equal\n",
    "    #weight in the composite. You could consider changing the weights based on \n",
    "    #historical statistical significance or whatever else seems reasonable\n",
    "\n",
    "    #This particular scoring system only invests in companies with \n",
    "    #positive trend/momentum after ranking by the other factors\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Total Score'] = Data_for_Portfolio_master_filter['Valuation Score'] +  \\\n",
    "        Data_for_Portfolio_master_filter['Quality Score'] + Data_for_Portfolio_master_filter['Shareholder Yield Score'] +\\\n",
    "        Data_for_Portfolio_master_filter['Momentum Score'] + Data_for_Portfolio_master_filter['Trend Score']\n",
    "    \n",
    "    \n",
    "    \n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.sort_values('Total Score', ascending=False)\n",
    "    \n",
    "    top_rated_company = Data_for_Portfolio_master_filter[:int(len(Data_for_Portfolio_master_filter) \\\n",
    "                                                              * Percentile_split)].index.tolist()\n",
    "    top_rated_company\n",
    "\n",
    "    low_rated_company = Data_for_Portfolio_master_filter[-int(len(Data_for_Portfolio_master_filter) \\\n",
    "                                                              * Percentile_split):].index.tolist()\n",
    "    low_rated_company\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    start_hayoo = str(int(start)+i+1)+'-1-1'\n",
    "    end_hayoo = str(int(start)+i+2)+'-1-1'\n",
    "    \n",
    "    cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod()\n",
    "    running_max_BH = np.maximum.accumulate(cum_str_returns_bh[1:].fillna(method='backfill') )\n",
    "    drawdown_BH = (cum_str_returns_bh[1:])/running_max_BH - 1\n",
    "    max_dd = drawdown_BH.min()*100\n",
    "\n",
    "\n",
    "    try:\n",
    "        Data_for_Portfolio_master_filter['Max DD'] = max_dd.values \n",
    "    except:\n",
    "        Data_for_Portfolio_master_filter['Max DD'] = [max_dd]\n",
    "    \n",
    "    max_dd_list.append(max_dd.min())\n",
    "    \n",
    "#     # == Доходность\n",
    "    \n",
    "    portfolio_profit = [] \n",
    "    profit_list_index = 0\n",
    "\n",
    "    top_rated_company_yahoo = []\n",
    "    low_rated_company_yahoo = []\n",
    "    \n",
    "    \n",
    "    for tic in top_rated_company:\n",
    "        top_rated_company_yahoo.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "        \n",
    "    for tic in low_rated_company:\n",
    "        low_rated_company_yahoo.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "        \n",
    "  \n",
    "    \n",
    "#     profit_yah = yf.download(top_rated_company, start_hayoo, end_hayoo)['Adj Close'].fillna(method='backfill') \n",
    "    profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i)]\n",
    "    profit = (profit_yah.iloc[-1]-profit_yah.iloc[0])/profit_yah.iloc[0]\n",
    "#     profit_yah['profit'] = profit\n",
    "    portfolio_profit = profit.values.tolist()\n",
    "#     print(profit_yah)\n",
    "            \n",
    "    \n",
    "#     for company in top_rated_company:\n",
    "# #         print('tut1')\n",
    "#         try:\n",
    "#             profit_yah = yf.download(company, start_hayoo, end_hayoo)['Adj Close'].fillna(method='backfill') \n",
    "#             profit = (profit_yah[-1]-profit_yah[0])/profit_yah[0]\n",
    "#             (1 + profit).cumprod()[-1]\n",
    "#             portfolio_profit.append(profit)\n",
    "#             print(profit)\n",
    "#         except:\n",
    "#             pass\n",
    "#     portfolio_profit\n",
    "\n",
    "\n",
    "#     profit_list_index = 0\n",
    "\n",
    "    profit_yah_index = yf.download(index)['Adj Close'].fillna(method='backfill')[str(int(start)+i)] \n",
    "    profit_index = (profit_yah_index[-1]-profit_yah_index[0])/profit_yah_index[0]\n",
    "\n",
    "    \n",
    "\n",
    "    print('Год начальный')\n",
    "    print(start_hayoo)\n",
    "    \n",
    "#     profit_list_index = profit_index\n",
    "\n",
    "    portfolio_profit_final.append(np.mean(portfolio_profit)*100)\n",
    "    index_profit_final.append(profit_index*100)\n",
    "\n",
    "#     returnezzz = pd.DataFrame()\n",
    "#     returnezzz['Portfolio'] = [np.mean(portfolio_profit)*100]\n",
    "#     returnezzz['Index'] = [profit_list_index*100]\n",
    "\n",
    "    print(portfolio_profit_final)\n",
    "\n",
    "    print('top_rated_company')\n",
    "    print(top_rated_company)\n",
    "    print('low_rated_company')\n",
    "    print(low_rated_company)\n",
    "       \n",
    "\n",
    "    print('Max DD')\n",
    "    print(max_dd_list)\n",
    "    print(np.min(max_dd_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returnez_cum_port = pd.DataFrame(portfolio_profit_final).dropna()  \n",
    "returnez_cum_index = pd.DataFrame(index_profit_final).dropna()  \n",
    "\n",
    "returnez = pd.DataFrame()\n",
    "\n",
    "returnez['Страна'] = [LIST]\n",
    "returnez['Начало периода'] = [cheked_year]\n",
    "returnez['Дходность с ребалансировкой портфеля'] = ((1 + (returnez_cum_port/100)).cumprod().iloc[-1]-1)*100\n",
    "returnez['Дходность Индекса'] = ((1 + (returnez_cum_index/100)).cumprod().iloc[-1]-1)*100\n",
    "returnez['Max DD'] = [np.min(max_dd_list)]\n",
    "\n",
    "# gc = gd.service_account(filename='Seetzzz-1cb93f64d8d7.json')\n",
    "# worksheet = gc.open(\"Тесты бэктестинга\").worksheet('Мульти-фактор2')\n",
    "\n",
    "# worksheet.update('A20', [returnez.columns.tolist()] + returnez.values.tolist())\n",
    "\n",
    "returnez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_for_Portfolio_master_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_yahoo_main['ABBN.ME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
