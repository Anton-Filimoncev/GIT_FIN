{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from pandas_datareader.famafrench import get_available_datasets\n",
    "import pandas_datareader.data as web\n",
    "from yahoo_fin import stock_info as si\n",
    "from performance_analysis import annualized_return\n",
    "from performance_analysis import annualized_standard_deviation\n",
    "from performance_analysis import max_drawdown\n",
    "from performance_analysis import gain_to_pain_ratio\n",
    "from performance_analysis import calmar_ratio\n",
    "from performance_analysis import sharpe_ratio\n",
    "from performance_analysis import sortino_ratio\n",
    "import yfinance as yf\n",
    "import apiclient.discovery\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import httplib2\n",
    "from sklearn import mixture as mix\n",
    "import seaborn as sns \n",
    "import gspread as gd\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSE:RDSA', 'LSE:RDSB', 'LSE:BTA', 'LSE:RSW', 'LSE:HLMA', 'LSE:JET', 'LSE:BP', 'LSE:PSH', 'LSE:PSN', 'LSE:WPP', 'LSE:BME', 'LSE:SKG', 'LSE:KGF', 'LSE:SGE', 'LSE:UU', 'LSE:ICP', 'LSE:RMV', 'LSE:FLTR', 'LSE:DCC', 'LSE:ENT', 'LSE:SMT', 'LSE:AUTO', 'LSE:SGRO', 'LSE:SSE', 'LSE:EXPN', 'LSE:AVV', 'LSE:SBRY', 'LSE:REL', 'LSE:HSBA', 'LSE:ITRK', 'LSE:HIK', 'LSE:NXT', 'LSE:LAND', 'LSE:BARC', 'LSE:PSON', 'LSE:LGEN', 'LSE:CCH', 'LSE:CRDA', 'LSE:HL', 'LSE:RKT', 'LSE:TSCO', 'LSE:ADM', 'LSE:IMB', 'LSE:RTO', 'LSE:BDEV', 'LSE:AVST', 'LSE:SMDS', 'LSE:SVT', 'LSE:FERG', 'LSE:ULVR', 'LSE:SPX', 'LSE:SMIN', 'LSE:OCDO', 'LSE:PRU', 'LSE:MNDI', 'LSE:BLND', 'LSE:LSEG', 'LSE:BRBY', 'LSE:DGE', 'LSE:BA', 'LSE:AV', 'LSE:ANTO', 'LSE:STAN', 'LSE:NG', 'LSE:SN', 'LSE:BATS', 'LSE:GSK', 'LSE:AZN', 'LSE:MRO', 'LSE:TW', 'LSE:SDR', 'LSE:MNG', 'LSE:BKG', 'LSE:AHT', 'LSE:LLOY', 'LSE:CPG', 'LSE:VOD', 'LSE:STJ', 'LSE:CRH', 'LSE:PHNX', 'LSE:BNZL', 'LSE:WEIR', 'LSE:JD', 'LSE:NWG', 'LSE:SLA', 'LSE:BHP', 'LSE:III', 'LSE:RIO', 'LSE:WTB', 'LSE:EVR', 'LSE:IHG', 'LSE:GLEN', 'LSE:AAL', 'LSE:RMG', 'LSE:JMAT', 'LSE:ABF', 'LSE:POLY', 'LSE:FRES', 'LSE:INF', 'LSE:IAG', 'LSE:RR']\n"
     ]
    }
   ],
   "source": [
    "# подключение к гугл таблице\n",
    "\n",
    "LIST = 'Британия'\n",
    "\n",
    "index = '^AXJO'\n",
    "\n",
    "exchange = 'LSE:'\n",
    "\n",
    "exchange_yahoo =  '.L'\n",
    "\n",
    "# tickers = si.tickers_sp500()\n",
    "cheked_year = '2015' \n",
    "cheked_year_end = '2020' \n",
    "\n",
    "\n",
    "# Файл, полученный в Google Developer Console\n",
    "CREDENTIALS_FILE = 'Seetzzz-1cb93f64d8d7.json'\n",
    "# ID Google Sheets документа (можно взять из его URL)\n",
    "spreadsheet_id = '1lDhu6-tBmoh66a1mY3RU2yPV2_3uIzNSQWNI5UtMcag'\n",
    "spreadsheet_id2 = '1A3leW6ZfsoVEPXZsv0Loj4eAbyKRchnHrJLdP4RIXDA'\n",
    "#\n",
    "# Авторизуемся и получаем service — экземпляр доступа к API\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "    CREDENTIALS_FILE,\n",
    "    ['https://www.googleapis.com/auth/spreadsheets',\n",
    "     'https://www.googleapis.com/auth/drive'])\n",
    "httpAuth = credentials.authorize(httplib2.Http())\n",
    "service = apiclient.discovery.build('sheets', 'v4', http=httpAuth)\n",
    "\n",
    "# ____________________________Парсим тикеры !!!!С ТАБЛИЦЫ!!!! и работаем с ними _______________________________________\n",
    "\n",
    "# Чтения файла\n",
    "values = service.spreadsheets().values().get(\n",
    "    spreadsheetId=spreadsheet_id,\n",
    "    range=f'{LIST}!A1:AA1000',\n",
    "    majorDimension='COLUMNS'\n",
    ").execute()\n",
    "\n",
    "tickers = values['values'][3][1:]\n",
    "\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  38 of 38 completed\n"
     ]
    }
   ],
   "source": [
    "yahoo_ticker_list_full = []\n",
    "\n",
    "for tic in tickers:\n",
    "    yahoo_ticker_list_full.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "\n",
    "    \n",
    "price_yahoo_pre_main = yf.download(yahoo_ticker_list_full)\n",
    "price_yahoo_pre_main = price_yahoo_pre_main['Adj Close'].fillna(method='ffill').fillna(0)\n",
    "\n",
    "company_yahoo_found = price_yahoo_pre_main.sum()[(price_yahoo_pre_main.sum()!=0)].index.tolist()\n",
    "\n",
    "tickers = []\n",
    "# tickers_ttt = \n",
    "for y_comp in company_yahoo_found:\n",
    "    tickers.append(exchange + y_comp.replace(exchange_yahoo, ''))\n",
    "# price_yahoo_main = yf.download(company_yahoo_found)\n",
    "# price_yahoo_main = price_yahoo_main['Adj Close'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Читаем данные из огурцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSE:BTA\n",
      "LSE:BP\n",
      "LSE:UU\n",
      "LSE:HL\n",
      "LSE:BA\n",
      "LSE:AV\n",
      "LSE:NG\n",
      "LSE:SN\n",
      "LSE:TW\n",
      "LSE:JD\n",
      "LSE:SLA\n",
      "LSE:RR\n"
     ]
    }
   ],
   "source": [
    "# # ['annuals']\n",
    "\n",
    "Data_for_Portfolio_TOTAL = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    with open(f'''C:/Users/Anton/Desktop/Backtesting/BANKA/data_json_{ticker.replace(exchange, '')}.pickle''', 'rb') as f:\n",
    "        data_json = pickle.load(f)\n",
    "\n",
    "    with open(f'''C:/Users/Anton/Desktop/Backtesting/BANKA/data_json_keyratios_{ticker.replace(exchange, '')}.pickle''', 'rb') as f:\n",
    "        data_json_keyratios = pickle.load(f)\n",
    "\n",
    "#     print(data_json)    \n",
    "    try:\n",
    "        date_list = pd.Series(data_json['financials']['annuals']['Fiscal Year'])\n",
    "        keyratios = pd.DataFrame(data_json_keyratios['Fundamental'], index=[0]) \n",
    "        income_df = pd.DataFrame(data_json['financials']['annuals']['income_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('', 0).replace('N/A', 0).astype(float)\n",
    "        balance_df = pd.DataFrame(data_json['financials']['annuals']['balance_sheet']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        cashflow_df = pd.DataFrame(data_json['financials']['annuals']['cashflow_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        valuation_ratios_df = pd.DataFrame(data_json['financials']['annuals']['valuation_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        valuation_and_quality_df = pd.DataFrame(data_json['financials']['annuals']['valuation_and_quality']).set_index(date_list).drop(['Restated Filing Date', 'Filing Date', 'Earnings Release Date'], axis=1).replace('', 0).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        common_size_ratios_df = pd.DataFrame(data_json['financials']['annuals']['common_size_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).replace('Negative Tangible Equity', 0).astype(float)\n",
    "        # per_share_data_array_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        per_share_data_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('', 0).replace('No Debt', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        \n",
    "        check = 1\n",
    "    except:\n",
    "        check = 0\n",
    "        print(ticker)\n",
    "        \n",
    "        pass\n",
    "            \n",
    "    if check == 1:\n",
    "    \n",
    "        try:\n",
    "            Data_for_Portfolio = pd.DataFrame()\n",
    "        #     \n",
    "            Data_for_Portfolio['E/P'] = income_df['Net Income'] / valuation_and_quality_df['Market Cap'] \n",
    "            # income_df['Net Income']\n",
    "            # valuation_and_quality_df.replace('-', 0)\n",
    "\n",
    "\n",
    "#             Data_for_Portfolio['EBITDA/EV'] = income_df['EBITDA'] / (valuation_and_quality_df['Enterprise Value ($M)']*1000000)\n",
    "            \n",
    "            Data_for_Portfolio['EBITDA/EV'] = 1/valuation_ratios_df['EV-to-EBITDA']\n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['ncfcommon'] = cashflow_df['Free Cash Flow']/valuation_and_quality_df['Shares Outstanding (EOP)']\n",
    "\n",
    "            Data_for_Portfolio['Total Debt'] = (balance_df['Short-Term Debt'] + balance_df['Long-Term Debt'])\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['Shareholder Yield'] = -((Data_for_Portfolio['Total Debt'] + cashflow_df['Free Cash Flow'] \\\n",
    "                                             + Data_for_Portfolio['ncfcommon']) / valuation_and_quality_df['Market Cap'])\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['FCF/P'] = cashflow_df['Free Cash Flow'] / valuation_and_quality_df['Market Cap']\n",
    "            Data_for_Portfolio\n",
    "            # Data_for_Portfolio['Shareholder Yield'] \n",
    "            Data_for_Portfolio['Book Value per Share'] = per_share_data_df['Book Value per Share']\n",
    "            Data_for_Portfolio['Dividends per Share'] =per_share_data_df['Dividends per Share'] \n",
    "            Data_for_Portfolio['Dividend Payout Ratio'] =common_size_ratios_df['Dividend Payout Ratio']\n",
    "\n",
    "            Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Current Assets']\n",
    "\n",
    "            #Can you generate returns on investment?   \n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['ROA'] = common_size_ratios_df['ROA %']  \n",
    "            Data_for_Portfolio['ROIC'] = common_size_ratios_df['ROIC %']\n",
    "            #Do you have a defendable business model?\n",
    "\n",
    "            Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Gross Margin %']\n",
    "\n",
    "            Data_for_Portfolio['CURRENT RATIO'] = balance_df['Total Current Assets'] / balance_df['Total Current Liabilities']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['EBITDA']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            Data_for_Portfolio['Company'] = ticker\n",
    "            Data_for_Portfolio['Date'] = list(date_list)\n",
    "\n",
    "            Data_for_Portfolio = Data_for_Portfolio.replace([np.inf, -np.inf], 0)\n",
    "            Data_for_Portfolio = Data_for_Portfolio.set_index('Company')\n",
    "            Data_for_Portfolio = Data_for_Portfolio[::-1]\n",
    "\n",
    "            sumz_frame= [Data_for_Portfolio, Data_for_Portfolio_TOTAL]\n",
    "            Data_for_Portfolio_TOTAL = pd.concat(sumz_frame)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "#         print(list(date_list))\n",
    "# list(set(Data_for_Portfolio_TOTAL.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(Data_for_Portfolio_TOTAL.index.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(Data_for_Portfolio_TOTAL.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ['annuals']\n",
    "\n",
    "# tickers = si.tickers_sp500()\n",
    "\n",
    "# Data_for_Portfolio_TOTAL = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# for ticker in tickers:\n",
    "#     with open(f'BANKA/data_json_{ticker}.pickle', 'rb') as f:\n",
    "#         data_json = pickle.load(f)\n",
    "\n",
    "#     with open(f'BANKA/data_json_keyratios_{ticker}.pickle', 'rb') as f:\n",
    "#         data_json_keyratios = pickle.load(f)\n",
    "\n",
    "# #     print(data_json)    \n",
    "#     try:\n",
    "#         date_list = pd.Series(data_json['financials']['annuals']['Fiscal Year'])\n",
    "#         keyratios = pd.DataFrame(data_json_keyratios['Fundamental'], index=[0]) \n",
    "#         income_df = pd.DataFrame(data_json['financials']['annuals']['income_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('', 0).replace('N/A', 0).astype(float)\n",
    "#         balance_df = pd.DataFrame(data_json['financials']['annuals']['balance_sheet']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         cashflow_df = pd.DataFrame(data_json['financials']['annuals']['cashflow_statement']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         valuation_ratios_df = pd.DataFrame(data_json['financials']['annuals']['valuation_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         valuation_and_quality_df = pd.DataFrame(data_json['financials']['annuals']['valuation_and_quality']).set_index(date_list).drop(['Restated Filing Date', 'Filing Date', 'Earnings Release Date'], axis=1).replace('', 0).replace('No Debt', 0).replace('At Loss', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         common_size_ratios_df = pd.DataFrame(data_json['financials']['annuals']['common_size_ratios']).set_index(date_list).replace('No Debt', 0).replace('At Loss', 0).replace('', 0).replace('-', 0).replace('N/A', 0).replace('Negative Tangible Equity', 0).astype(float)\n",
    "#         # per_share_data_array_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "#         per_share_data_df = pd.DataFrame(data_json['financials']['annuals']['per_share_data_array']).set_index(date_list).replace('', 0).replace('No Debt', 0).replace('-', 0).replace('N/A', 0).astype(float)\n",
    "        \n",
    "#         check = 1\n",
    "#     except:\n",
    "#         pass\n",
    "            \n",
    "#     if check == 1:\n",
    "    \n",
    "#         Data_for_Portfolio = pd.DataFrame()\n",
    "#     #     \n",
    "#         Data_for_Portfolio['E/P'] = income_df['Net Income'] / valuation_and_quality_df['Market Cap'] \n",
    "#         # income_df['Net Income']\n",
    "#         # valuation_and_quality_df.replace('-', 0)\n",
    "#         Data_for_Portfolio\n",
    "#         try:\n",
    "#             Data_for_Portfolio['EBITDA/EV'] = income_df['EBITDA'] / (valuation_and_quality_df['Enterprise Value ($M)']*1000000)\n",
    "#         except:\n",
    "#             Data_for_Portfolio['EBITDA/EV'] = Data_for_Portfolio['E/P'] * 0\n",
    "\n",
    "#         Data_for_Portfolio['ncfcommon'] = cashflow_df['Free Cash Flow']/valuation_and_quality_df['Shares Outstanding (EOP)']\n",
    "#         try:\n",
    "#             Data_for_Portfolio['Total Debt'] = (balance_df['Short-Term Debt'] + balance_df['Long-Term Debt'])\n",
    "#         except:\n",
    "#             Data_for_Portfolio['Total Debt'] = Data_for_Portfolio['ncfcommon'] * 0\n",
    "# #             print(Data_for_Portfolio)\n",
    "\n",
    "#         Data_for_Portfolio['Shareholder Yield'] = -((Data_for_Portfolio['Total Debt'] + cashflow_df['Free Cash Flow'] \\\n",
    "#                                          + Data_for_Portfolio['ncfcommon']) / valuation_and_quality_df['Market Cap'])\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['FCF/P'] = cashflow_df['Free Cash Flow'] / valuation_and_quality_df['Market Cap']\n",
    "#         Data_for_Portfolio\n",
    "#         # Data_for_Portfolio['Shareholder Yield'] \n",
    "#         Data_for_Portfolio['Book Value per Share'] = per_share_data_df['Book Value per Share']\n",
    "#         Data_for_Portfolio['Dividends per Share'] =per_share_data_df['Dividends per Share'] \n",
    "#         Data_for_Portfolio['Dividend Payout Ratio'] =common_size_ratios_df['Dividend Payout Ratio']\n",
    "\n",
    "#         try:\n",
    "#             Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Current Assets']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['FCF/Assets'] = cashflow_df['Free Cash Flow'] / balance_df['Total Assets']\n",
    "#         #Can you generate returns on investment?   \n",
    "\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['ROA'] = common_size_ratios_df['ROA %']  \n",
    "#         Data_for_Portfolio['ROIC'] = common_size_ratios_df['ROIC %']\n",
    "#         #Do you have a defendable business model?\n",
    "#         try:\n",
    "#             Data_for_Portfolio['GROSS MARGIN'] = common_size_ratios_df['Gross Margin %']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['GROSS MARGIN'] = Data_for_Portfolio['ROA'] * 0\n",
    "#         #Current Financial Strength\n",
    "#         try:\n",
    "#             Data_for_Portfolio['CURRENT RATIO'] = balance_df['Total Current Assets'] / balance_df['Total Current Liabilities']\n",
    "#         except:\n",
    "#             Data_for_Portfolio['CURRENT RATIO'] = balance_df['Total Assets'] / balance_df['Total Liabilities']\n",
    "\n",
    "\n",
    "#         try:\n",
    "#             Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / income_df['EBITDA']\n",
    "#         except:\n",
    "#             try:\n",
    "#                 Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense (Positive)'] / income_df['EBITDA']\n",
    "#             except:\n",
    "#                 Data_for_Portfolio['INTEREST/EBITDA'] = income_df['Interest Expense'] / 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         Data_for_Portfolio['Company'] = ticker\n",
    "#         Data_for_Portfolio['Date'] = list(date_list)\n",
    "\n",
    "#         Data_for_Portfolio = Data_for_Portfolio.replace([np.inf, -np.inf], 0)\n",
    "#         Data_for_Portfolio = Data_for_Portfolio.set_index('Company')\n",
    "#         Data_for_Portfolio = Data_for_Portfolio[::-1]\n",
    "\n",
    "#         sumz_frame= [Data_for_Portfolio, Data_for_Portfolio_TOTAL]\n",
    "#         Data_for_Portfolio_TOTAL = pd.concat(sumz_frame)\n",
    "\n",
    "\n",
    "\n",
    "# #         print(list(date_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  101 of 101 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "- SLA.L: No data found, symbol may be delisted\n",
      "- BTA.L: 1d data not available for startTime=-2208988800 and endTime=1631539104. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AVST.L: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RKT.L: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JET.L: Data doesn't exist for startDate = 1356987600, endDate = 1451595600\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:313: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-9-7b8f81555159>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod().fillna(0)\n",
      "<ipython-input-9-7b8f81555159>:381: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2016-1-1\n",
      "[29.392978759955074]\n",
      "top_rated_company\n",
      "['LSE:AUTO', 'LSE:MRO', 'LSE:RMV', 'LSE:IHG', 'LSE:NXT', 'LSE:RSW', 'LSE:FLTR', 'LSE:SGRO', 'LSE:LAND', 'LSE:SPX', 'LSE:PSN', 'LSE:BATS', 'LSE:BRBY', 'LSE:VOD']\n",
      "low_rated_company\n",
      "['LSE:RDSB', 'LSE:RDSA', 'LSE:BHP', 'LSE:EVR', 'LSE:IMB', 'LSE:SSE', 'LSE:ANTO', 'LSE:OCDO', 'LSE:TSCO', 'LSE:ITRK', 'LSE:JET', 'LSE:WEIR', 'LSE:GLEN', 'LSE:AAL']\n",
      "Max DD\n",
      "[-45.582689509514104]\n",
      "-45.582689509514104\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AVST.L: Data doesn't exist for startDate = 1388523600, endDate = 1483218000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RKT.L: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:313: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-9-7b8f81555159>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod().fillna(0)\n",
      "<ipython-input-9-7b8f81555159>:381: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2017-1-1\n",
      "[29.392978759955074, 23.96641984153595]\n",
      "top_rated_company\n",
      "['LSE:AUTO', 'LSE:RMV', 'LSE:NXT', 'LSE:PSN', 'LSE:BDEV', 'LSE:BKG', 'LSE:POLY', 'LSE:BHP', 'LSE:BRBY', 'LSE:SPX', 'LSE:MNDI', 'LSE:VOD', 'LSE:FRES', 'LSE:AHT']\n",
      "low_rated_company\n",
      "['LSE:IMB', 'LSE:LSEG', 'LSE:BLND', 'LSE:FLTR', 'LSE:AVST', 'LSE:GLEN', 'LSE:ENT', 'LSE:RDSB', 'LSE:RDSA', 'LSE:JET', 'LSE:PSON', 'LSE:TSCO', 'LSE:OCDO', 'LSE:MRO']\n",
      "Max DD\n",
      "[-45.582689509514104, -99.10486292153631]\n",
      "-99.10486292153631\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- AVST.L: Data doesn't exist for startDate = 1420059600, endDate = 1514754000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RKT.L: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:313: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-9-7b8f81555159>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod().fillna(0)\n",
      "<ipython-input-9-7b8f81555159>:381: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2018-1-1\n",
      "[29.392978759955074, 23.96641984153595, -1.7618903155453864]\n",
      "top_rated_company\n",
      "['LSE:AUTO', 'LSE:RMV', 'LSE:BKG', 'LSE:BATS', 'LSE:PSN', 'LSE:RIO', 'LSE:AAL', 'LSE:BRBY', 'LSE:RTO', 'LSE:AHT', 'LSE:BDEV', 'LSE:EVR', 'LSE:IAG', 'LSE:NXT']\n",
      "low_rated_company\n",
      "['LSE:AVST', 'LSE:WEIR', 'LSE:GSK', 'LSE:IMB', 'LSE:GLEN', 'LSE:SMDS', 'LSE:SSE', 'LSE:KGF', 'LSE:HIK', 'LSE:LAND', 'LSE:TSCO', 'LSE:WPP', 'LSE:JET', 'LSE:OCDO']\n",
      "Max DD\n",
      "[-45.582689509514104, -99.10486292153631, -54.2453547756804]\n",
      "-99.10486292153631\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RKT.L: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:313: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-9-7b8f81555159>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod().fillna(0)\n",
      "<ipython-input-9-7b8f81555159>:381: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2019-1-1\n",
      "[29.392978759955074, 23.96641984153595, -1.7618903155453864, 33.55660992421904]\n",
      "top_rated_company\n",
      "['LSE:AUTO', 'LSE:EVR', 'LSE:RMV', 'LSE:RIO', 'LSE:PSN', 'LSE:BKG', 'LSE:BDEV', 'LSE:AAL', 'LSE:BHP', 'LSE:RSW', 'LSE:NXT', 'LSE:BRBY', 'LSE:BATS', 'LSE:IAG']\n",
      "low_rated_company\n",
      "['LSE:INF', 'LSE:DCC', 'LSE:SMDS', 'LSE:TSCO', 'LSE:OCDO', 'LSE:ENT', 'LSE:SSE', 'LSE:WEIR', 'LSE:SVT', 'LSE:WPP', 'LSE:JET', 'LSE:BLND', 'LSE:LAND', 'LSE:MRO']\n",
      "Max DD\n",
      "[-45.582689509514104, -99.10486292153631, -54.2453547756804, -49.089929682868494]\n",
      "-99.10486292153631\n",
      "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:169: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RKT.L: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7b8f81555159>:313: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
      "<ipython-input-9-7b8f81555159>:350: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod().fillna(0)\n",
      "<ipython-input-9-7b8f81555159>:381: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Год начальный\n",
      "2020-1-1\n",
      "[29.392978759955074, 23.96641984153595, -1.7618903155453864, 33.55660992421904, 8.450973901947664]\n",
      "top_rated_company\n",
      "['LSE:AUTO', 'LSE:RMV', 'LSE:WTB', 'LSE:SDR', 'LSE:PSN', 'LSE:RIO', 'LSE:AHT', 'LSE:NXT', 'LSE:BDEV', 'LSE:VOD', 'LSE:BATS', 'LSE:BHP', 'LSE:AAL', 'LSE:POLY']\n",
      "low_rated_company\n",
      "['LSE:LSEG', 'LSE:SVT', 'LSE:WPP', 'LSE:ENT', 'LSE:MRO', 'LSE:TSCO', 'LSE:GLEN', 'LSE:SSE', 'LSE:OCDO', 'LSE:WEIR', 'LSE:RKT', 'LSE:JET', 'LSE:LAND', 'LSE:BLND']\n",
      "Max DD\n",
      "[-45.582689509514104, -99.10486292153631, -54.2453547756804, -49.089929682868494, -99.41513158223823]\n",
      "-99.41513158223823\n"
     ]
    }
   ],
   "source": [
    "# tickers = ['AAPL', 'INTC']\n",
    "\n",
    "yahoo_ticker_list_full = []\n",
    "\n",
    "for tic in tickers:\n",
    "    yahoo_ticker_list_full.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "\n",
    "price_yahoo_main = yf.download(yahoo_ticker_list_full)\n",
    "price_yahoo_main = price_yahoo_main['Adj Close'].fillna(method='backfill')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "years_len = int(cheked_year_end) - int(cheked_year)\n",
    "\n",
    "portfolio_profit_final = []\n",
    "index_profit_final = []\n",
    "max_dd_list = []\n",
    "\n",
    "\n",
    "Percentile_split = .2\n",
    "\n",
    "Winsorize_Threshold = .025\n",
    "\n",
    "# for i in range(years_len):\n",
    "for i in range(years_len):\n",
    "    print('i'*50)\n",
    "    print(i)\n",
    "\n",
    "    df_res = pd.DataFrame()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "\n",
    "            Data_for_Portfolio_tick = Data_for_Portfolio_TOTAL.loc[ticker].fillna(0).iloc[int(cheked_year_end) - (int(cheked_year)-1+i)]\n",
    "#             print(Data_for_Portfolio_tick)\n",
    "            sum_frame = [pd.DataFrame([Data_for_Portfolio_tick]), df_res]\n",
    "            df_res = pd.concat(sum_frame )  \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    Data_for_Portfolio_master_filter = df_res\n",
    "    \n",
    "    yahoo_ticker_list = []\n",
    "\n",
    "    for tic in Data_for_Portfolio_master_filter.index.tolist():\n",
    "        yahoo_ticker_list.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "         \n",
    "\n",
    "   #Winsorize the metric data and compress outliers if desired\n",
    "    Data_for_Portfolio_master_filter['E/P Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['E/P'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['EBITDA/EV Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['EBITDA/EV'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['FCF/P Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['FCF/P'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "\n",
    "    #create Z score to normalize the metrics\n",
    "    Data_for_Portfolio_master_filter['E/P Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['E/P Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['EBITDA/EV Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['EBITDA/EV Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['FCF/P Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['FCF/P Winsorized'])\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Valuation Score'] = \\\n",
    "            Data_for_Portfolio_master_filter['E/P Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['EBITDA/EV Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['FCF/P Z score']\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/P Winsorized']\n",
    "\n",
    "    ###### QUALITY FACTOR ######  \n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/Assets Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['FCF/Assets'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['ROA Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['ROA'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['ROIC Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['ROIC'], \\\n",
    "                                limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Gross Margin Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['GROSS MARGIN'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Current Ratio Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['CURRENT RATIO'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Interest/EBITDA Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['INTEREST/EBITDA'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "\n",
    "    #create Z score\n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['FCF/Assets Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['FCF/Assets Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['ROA Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['ROA Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['ROIC Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['ROIC Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Gross Margin Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Gross Margin Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Current Ratio Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Current Ratio Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Interest/EBITDA Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Interest/EBITDA Winsorized'])\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Quality Score'] = \\\n",
    "        Data_for_Portfolio_master_filter['FCF/Assets Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['ROA Z score'] \\\n",
    "            + Data_for_Portfolio_master_filter['ROIC Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['Gross Margin Z score']\\\n",
    "            + Data_for_Portfolio_master_filter['Current Ratio Z score']\\\n",
    "            - Data_for_Portfolio_master_filter['Interest/EBITDA Z score']\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    ###### SHAREHOLDER YIELD FACTOR #####\n",
    "\n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Winsorized'] = \\\n",
    "        stats.mstats.winsorize(Data_for_Portfolio_master_filter['Shareholder Yield'], \\\n",
    "                               limits=Winsorize_Threshold)\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Z score'] = \\\n",
    "        stats.zscore(Data_for_Portfolio_master_filter['Shareholder Yield Winsorized'])\n",
    "    Data_for_Portfolio_master_filter['Shareholder Yield Score'] = \\\n",
    "        Data_for_Portfolio_master_filter['Shareholder Yield Z score'] \n",
    "        \n",
    "        \n",
    "        ###### LOW VOLATILITY FACTOR ######\n",
    "\n",
    "    #must have fundamental data from previous factors for price based factors\n",
    "    #as some equities have price data and no fundamental data which should not\n",
    "    #be included\n",
    "\n",
    "    # treasury = 'RGBI.ME'\n",
    "    start = cheked_year\n",
    "    # end = current_date\n",
    "    end =  cheked_year_end\n",
    "\n",
    "#     price_yahoo = yf.download(Data_for_Portfolio_master_filter.index.tolist())\n",
    "    price_yahoo = price_yahoo_main[yahoo_ticker_list]\n",
    "\n",
    "    Sector_stock_returns =  price_yahoo.pct_change()      \n",
    "\n",
    "    #create rolling vol metric for previous 2 years\n",
    "    Sector_stock_rolling_vol = Sector_stock_returns.rolling(252*2).std()\n",
    "\n",
    "    #Choose second to last trading day to look at previous vol   \n",
    "    #Sometimes the dates are off when trying to line up end of quarter and business\n",
    "    #days so to eliminate errors in the for loop I go to day of quarter, shift forward\n",
    "    #a business day and then go back two business days\n",
    "\n",
    "    \n",
    "\n",
    "    Filter_Vol_Signal = Sector_stock_rolling_vol[str(int(start)+i)].dropna()\n",
    "    \n",
    "    \n",
    "\n",
    "    # Filter_Vol_Signal_Sort = Filter_Vol_Signal.sort_values().dropna() # для цикла паска тикеров\n",
    "\n",
    "    #create z score and rank for the Volatility Factor\n",
    "    # frame = { 'Vol': Filter_Vol_Signal} \n",
    "\n",
    "    # Filter_Vol_Signal_df = pd.DataFrame(frame)\n",
    "    \n",
    "    \n",
    "#     print(pd.DataFrame(stats.zscore(Filter_Vol_Signal)).mean())\n",
    "#     print(pd.DataFrame(stats.zscore(Filter_Vol_Signal)))\n",
    "\n",
    "#     Filter_Vol_Signal = Filter_Vol_Signal.fillna(0)\n",
    "\n",
    "    # Filter_Vol_Signal_df['Vol Z Score'] = stats.zscore(Filter_Vol_Signal) \n",
    "    # Filter_Vol_Signal_df = Filter_Vol_Signal_df.reset_index()\n",
    "    # print(Filter_Vol_Signal_df)\n",
    "\n",
    "    \n",
    "    Data_for_Portfolio_master_filter['Vol Z Score'] = pd.DataFrame(stats.zscore(Filter_Vol_Signal)).fillna(0).mean().tolist()\n",
    "#     print(stats.zscore(Filter_Vol_Signal))\n",
    "    # Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.merge(Filter_Vol_Signal_df, how = 'inner', on = ['ticker']) \n",
    "\n",
    "    ###### TREND FACTOR #####\n",
    "    \n",
    "    total_trend_score = []\n",
    "    \n",
    "    for tic in yahoo_ticker_list:\n",
    "        try:\n",
    "            df = yf.download(tic, str(int(start)+i-2)+'-1-1', str(int(start)+i+1)+'-1-1')\n",
    "        #     print(df)\n",
    "            df = df[['Open', 'High', 'Low', 'Adj Close']]\n",
    "            df['open'] = df['Open'].shift(1)\n",
    "            df['high'] = df['High'].shift(1)\n",
    "            df['low'] = df['Low'].shift(1)\n",
    "            df['close'] = df['Adj Close'].shift(1)\n",
    "\n",
    "            df = df[['open', 'high', 'low', 'close']]\n",
    "            df = df.dropna()\n",
    "\n",
    "            unsup = mix.GaussianMixture(n_components=4,\n",
    "                                        covariance_type=\"spherical\",\n",
    "                                        n_init=100,\n",
    "                                        random_state=42)\n",
    "            unsup.fit(np.reshape(df, (-1, df.shape[1])))\n",
    "            regime = unsup.predict(np.reshape(df, (-1, df.shape[1])))\n",
    "            df['Return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "            Regimes = pd.DataFrame(regime, columns=['Regime'], index=df.index) \\\n",
    "                .join(df, how='inner') \\\n",
    "                .assign(market_cu_return=df.Return.cumsum()) \\\n",
    "                .reset_index(drop=False) \\\n",
    "                .rename(columns={'index': 'Date'})\n",
    "\n",
    "            order = [0, 1, 2, 3]\n",
    "        #     fig = sns.FacetGrid(data=Regimes, hue='Regime', hue_order=order, aspect=2, height=4)\n",
    "        #     fig.map(plt.scatter, 'Date', 'market_cu_return', s=4).add_legend()\n",
    "        #     plt.show()\n",
    "\n",
    "            mean_for_regime = []\n",
    "            cur_price = df['close'][-1]\n",
    "\n",
    "            total_position = 0\n",
    "\n",
    "            for j in order:\n",
    "                mean_for_regime.append(unsup.means_[j][0])\n",
    "    #             print('Mean for regime %i: '%i,unsup.means_[i][0])\n",
    "        #         print('Co-Variance for regime %i: '%i,(unsup.covariances_[i]))\n",
    "\n",
    "            mean_for_regime = np.sort(mean_for_regime)   \n",
    "            for val in  mean_for_regime:\n",
    "                if cur_price > val:\n",
    "                    total_position += 0.25\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            total_trend_score.append(total_position)\n",
    "    #         print(mean_for_regime)\n",
    "    #         print('cur_price')\n",
    "    #         print(cur_price)\n",
    "    #         print('total_position')\n",
    "    #         print(total_position)\n",
    "        except:\n",
    "            total_trend_score.append(0)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Trend Score'] = total_trend_score\n",
    "    \n",
    "    #This is a very simply way to see how much a stock is in a trend up or down\n",
    "    #You could easily make this more complex/robust but it would cost you in \n",
    "    #execution time\n",
    "#     df_sma_50 = price_yahoo.rolling(50).mean()\n",
    "#     df_sma_100 = price_yahoo.rolling(100).mean()\n",
    "#     df_sma_150 = price_yahoo.rolling(150).mean()\n",
    "#     df_sma_200 = price_yahoo.rolling(200).mean()\n",
    "\n",
    "\n",
    "#     Filter_Trend_Signal_50 = df_sma_50[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_100 = df_sma_100[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_150 = df_sma_150[str(int(cheked_year)+i)]\n",
    "#     Filter_Trend_Signal_200 = df_sma_200[str(int(cheked_year)+i)]\n",
    "\n",
    "#     Price_Signal = price_yahoo[str(int(cheked_year)+i)]\n",
    "\n",
    "#     SMA_all = pd.DataFrame()\n",
    "#     SMA_50 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_50,1,0)).mean()\n",
    "#     SMA_100 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_100,1,0)).mean()\n",
    "#     SMA_150 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_150,1,0)).mean()\n",
    "#     SMA_200 = pd.DataFrame(np.where(Price_Signal > Filter_Trend_Signal_200,1,0)).mean()\n",
    "\n",
    "#     SMA_all['SMA_50'] = SMA_50\n",
    "#     SMA_all['SMA_100'] = SMA_100\n",
    "#     SMA_all['SMA_150'] = SMA_150\n",
    "#     SMA_all['SMA_200'] = SMA_200\n",
    "#     SMA_all['Trend Score'] = np.mean(SMA_all, axis=1)\n",
    "\n",
    "#     # print(SMA_all)\n",
    "#     Data_for_Portfolio_master_filter['Trend Score'] = np.mean(SMA_all, axis=1).tolist()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ###### MOMENTUM FACTOR #####\n",
    "\n",
    "#     print('tut')\n",
    "    \n",
    "    # tickers_momentum = list(Sector_stock_prices_vol_df_1_wide.columns)\n",
    "    #from the academic literature of 12 months - 1 month momentum \n",
    "#     df_mom_11_months = price_yahoo[str(int(cheked_year)+i)].pct_change(22*11)\n",
    "#     Data_for_Portfolio_master_filter['Momentum Score'] = pd.DataFrame(stats.zscore(df_mom_11_months.iloc[242:])).fillna(0).mean().tolist()\n",
    "#     # Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.merge(Filter_MOM_df[['ticker','Momentum Score']], how = 'inner', on = ['ticker'])\n",
    "#     Data_for_Portfolio_master_filter\n",
    "\n",
    "\n",
    "\n",
    "    prices = price_yahoo_main[yahoo_ticker_list].asfreq('BM')\n",
    "    prices_yearly_returns = prices.pct_change(12)\n",
    "    prices_yearly_signal = np.where(prices_yearly_returns[str(int(cheked_year)+i)].iloc[-1] > 0, 1, 0)\n",
    "    Data_for_Portfolio_master_filter['Momentum Score'] = prices_yearly_signal\n",
    "\n",
    "    \n",
    "       \n",
    "    ### Create Composite Score from factors ###\n",
    "\n",
    "    #Because we made all the factors with a z score each factor should have equal\n",
    "    #weight in the composite. You could consider changing the weights based on \n",
    "    #historical statistical significance or whatever else seems reasonable\n",
    "\n",
    "    #This particular scoring system only invests in companies with \n",
    "    #positive trend/momentum after ranking by the other factors\n",
    "\n",
    "    Data_for_Portfolio_master_filter['Total Score'] = Data_for_Portfolio_master_filter['Valuation Score'] +  \\\n",
    "        Data_for_Portfolio_master_filter['Quality Score'] + Data_for_Portfolio_master_filter['Shareholder Yield Score'] +\\\n",
    "        Data_for_Portfolio_master_filter['Momentum Score'] + Data_for_Portfolio_master_filter['Trend Score']\n",
    "    \n",
    "    \n",
    "    \n",
    "    Data_for_Portfolio_master_filter = Data_for_Portfolio_master_filter.sort_values('Total Score', ascending=False)\n",
    "    \n",
    "    top_rated_company = Data_for_Portfolio_master_filter[:int(len(Data_for_Portfolio_master_filter) \\\n",
    "                                                              * Percentile_split)].index.tolist()\n",
    "    top_rated_company\n",
    "\n",
    "    low_rated_company = Data_for_Portfolio_master_filter[-int(len(Data_for_Portfolio_master_filter) \\\n",
    "                                                              * Percentile_split):].index.tolist()\n",
    "    low_rated_company\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    start_hayoo = str(int(start)+i+1)+'-1-1'\n",
    "    end_hayoo = str(int(start)+i+2)+'-1-1'\n",
    "    \n",
    "    cum_str_returns_bh = (price_yahoo[yahoo_ticker_list][str(int(start)+i+1)].fillna(method='backfill').pct_change() + 1).cumprod().fillna(0)\n",
    "    running_max_BH = np.maximum.accumulate(cum_str_returns_bh[1:].fillna(method='backfill') )\n",
    "    drawdown_BH = (cum_str_returns_bh[1:])/running_max_BH - 1\n",
    "    max_dd = drawdown_BH.min()*100\n",
    "\n",
    "\n",
    "    try:\n",
    "        Data_for_Portfolio_master_filter['Max DD'] = max_dd.values \n",
    "    except:\n",
    "        Data_for_Portfolio_master_filter['Max DD'] = [max_dd]\n",
    "    \n",
    "    max_dd_list.append(max_dd.min())\n",
    "    \n",
    "#     # == Доходность\n",
    "    \n",
    "    portfolio_profit = [] \n",
    "    profit_list_index = 0\n",
    "\n",
    "    top_rated_company_yahoo = []\n",
    "    low_rated_company_yahoo = []\n",
    "    \n",
    "    \n",
    "    for tic in top_rated_company:\n",
    "        top_rated_company_yahoo.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "        \n",
    "    for tic in low_rated_company:\n",
    "        low_rated_company_yahoo.append(tic.replace(exchange,'')+exchange_yahoo )\n",
    "        \n",
    "  \n",
    "    \n",
    "#     profit_yah = yf.download(top_rated_company, start_hayoo, end_hayoo)['Adj Close'].fillna(method='backfill') \n",
    "    profit_yah = price_yahoo_main[top_rated_company_yahoo][str(int(start)+i+1)].fillna(method='backfill') \n",
    "    profit = (profit_yah.iloc[-1]-profit_yah.iloc[0])/profit_yah.iloc[0]\n",
    "    profit = profit.dropna()\n",
    "#     profit_yah['profit'] = profit\n",
    "    portfolio_profit = profit.values.tolist()\n",
    "#     print(profit_yah)\n",
    "            \n",
    "    \n",
    "#     for company in top_rated_company:\n",
    "# #         print('tut1')\n",
    "#         try:\n",
    "#             profit_yah = yf.download(company, start_hayoo, end_hayoo)['Adj Close'].fillna(method='backfill') \n",
    "#             profit = (profit_yah[-1]-profit_yah[0])/profit_yah[0]\n",
    "#             (1 + profit).cumprod()[-1]\n",
    "#             portfolio_profit.append(profit)\n",
    "#             print(profit)\n",
    "#         except:\n",
    "#             pass\n",
    "#     portfolio_profit\n",
    "\n",
    "\n",
    "#     profit_list_index = 0\n",
    "\n",
    "    profit_yah_index = yf.download(index)['Adj Close'].fillna(method='backfill')[str(int(start)+i)] \n",
    "    profit_index = (profit_yah_index[-1]-profit_yah_index[0])/profit_yah_index[0]\n",
    "\n",
    "    \n",
    "\n",
    "    print('Год начальный')\n",
    "    print(start_hayoo)\n",
    "    \n",
    "#     profit_list_index = profit_index\n",
    "\n",
    "    portfolio_profit_final.append(np.mean(portfolio_profit)*100)\n",
    "    index_profit_final.append(profit_index*100)\n",
    "\n",
    "#     returnezzz = pd.DataFrame()\n",
    "#     returnezzz['Portfolio'] = [np.mean(portfolio_profit)*100]\n",
    "#     returnezzz['Index'] = [profit_list_index*100]\n",
    "\n",
    "    print(portfolio_profit_final)\n",
    "\n",
    "    print('top_rated_company')\n",
    "    print(top_rated_company)\n",
    "    print('low_rated_company')\n",
    "    print(low_rated_company)\n",
    "       \n",
    "\n",
    "    print('Max DD')\n",
    "    print(max_dd_list)\n",
    "    print(np.min(max_dd_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Страна</th>\n",
       "      <th>Начало периода</th>\n",
       "      <th>Дходность с ребалансировкой портфеля</th>\n",
       "      <th>Дходность Индекса</th>\n",
       "      <th>Max DD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Британия</td>\n",
       "      <td>2015</td>\n",
       "      <td>128.240973</td>\n",
       "      <td>24.126498</td>\n",
       "      <td>-99.415132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Страна Начало периода  Дходность с ребалансировкой портфеля  \\\n",
       "0  Британия           2015                            128.240973   \n",
       "\n",
       "   Дходность Индекса     Max DD  \n",
       "0          24.126498 -99.415132  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnez_cum_port = pd.DataFrame(portfolio_profit_final).dropna()  \n",
    "returnez_cum_index = pd.DataFrame(index_profit_final).dropna()  \n",
    "\n",
    "returnez = pd.DataFrame()\n",
    "\n",
    "returnez['Страна'] = [LIST]\n",
    "returnez['Начало периода'] = [cheked_year]\n",
    "returnez['Дходность с ребалансировкой портфеля'] = ((1 + (returnez_cum_port/100)).cumprod().iloc[-1]-1)*100\n",
    "returnez['Дходность Индекса'] = ((1 + (returnez_cum_index/100)).cumprod().iloc[-1]-1)*100\n",
    "returnez['Max DD'] = [np.min(max_dd_list)]\n",
    "\n",
    "# gc = gd.service_account(filename='Seetzzz-1cb93f64d8d7.json')\n",
    "# worksheet = gc.open(\"Тесты бэктестинга\").worksheet('Мульти-фактор2')\n",
    "\n",
    "# worksheet.update('A20', [returnez.columns.tolist()] + returnez.values.tolist())\n",
    "\n",
    "returnez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_str_returns_bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
